{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2611f12-ba1f-4369-9ec5-112e71532daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "from statsmodels.stats.weightstats import ztest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5d38d8-ad6b-4cdb-b3ab-9a6b5d1ef08a",
   "metadata": {},
   "source": [
    "## Test 1 Z-test for a population mean (variance known)\n",
    "\n",
    "Object\n",
    "To investigate the significance of the difference between an assumed population mean\n",
    "µ0 and a sample mean $\\overline{X}$.\n",
    "\n",
    "$Z = \\frac{\\bar{X} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "905b76b4-8bb4-4a31-b94e-4999f6e36ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z Statistic: 0.5741692517632145\n",
      "P-value: 0.5816333668955778\n",
      "Reject null hypothesis: False\n"
     ]
    }
   ],
   "source": [
    "population_mean = 100\n",
    "population_std = 3  \n",
    "x = ss.norm.rvs(100,9, size=20)\n",
    "# Performing Z-test\n",
    "z_statistic, p_value = ztest(x, value=population_mean, alternative='two-sided')\n",
    "print(\"Z-statistic:\", z_statistic)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed14375-c9e5-4865-910e-b031f9433ce4",
   "metadata": {},
   "source": [
    "## Test 2 Z-test for two population means (variances known and equal)\n",
    "\n",
    "To investigate the significance of the difference between the means of two populations\n",
    "\n",
    "$Z = \\frac{{\\bar{x}_1 - \\bar{x}_2}-(\\mu_1-\\mu_2)}{{\\sigma\\sqrt{\\frac{{1}}{{n_1}} + \\frac{{1}}{{n_2}}}}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d52e3f50-9c4a-474f-bbb5-971382f77a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z Statistic: 0.5741692517632145\n",
      "P-value: 0.5816333668955778\n",
      "Reject null hypothesis: False\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Example data\n",
    "sample1 = [25, 30, 35, 40, 45]\n",
    "sample2 = [20, 28, 32, 38, 42]\n",
    "\n",
    "# Define significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Perform Z-test for two population means\n",
    "z_statistic, p_value = stats.ttest_ind(sample1, sample2)\n",
    "\n",
    "# Determine if the null hypothesis should be rejected\n",
    "reject_null = p_value < alpha\n",
    "\n",
    "print(\"Z Statistic:\", z_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "print(\"Reject null hypothesis:\", reject_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7696e17-c9f1-480d-b977-73a6549bb0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score: 2.309401076758503\n",
      "P-value: 0.02092133533779403\n"
     ]
    }
   ],
   "source": [
    "def z_test_two_means(sample_mean1, sample_mean2, population_std, n1, n2):\n",
    "    se = population_std * ((1 / n1) + (1 / n2))**0.5\n",
    "    z = (sample_mean1 - sample_mean2) / se\n",
    "    p_value = 2 * ss.norm.cdf(-abs(z))  # two-tailed test\n",
    "    \n",
    "    return z, p_value\n",
    "\n",
    "# Example data\n",
    "sample_mean1 = 110 \n",
    "sample_mean2 = 100 \n",
    "population_std = 15\n",
    "n1 = 30  \n",
    "n2 = 20  \n",
    "\n",
    "# Perform Z-test\n",
    "z_score, p_value = z_test_two_means(sample_mean1, sample_mean2, population_std, n1, n2)\n",
    "print(\"Z-score:\", z_score)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e23934-5c24-489e-952a-ee524fcc8b38",
   "metadata": {},
   "source": [
    "## Test 3 Z-test for two population means (variancesknown and unequal)\n",
    "\n",
    "Object\n",
    "To investigate the significance of the difference between the means of two populations.\n",
    "\n",
    "$Z = \\frac{{\\bar{X}_1 - \\bar{X}_2}}{{\\sqrt{\\frac{{\\sigma_1^2}}{{n_1}} + \\frac{{\\sigma_2^2}}{{n_2}}}}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "694f1801-4008-43b3-b40e-b62fd1538454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T Statistic: 0.5741692517632145\n",
      "P-value: 0.5817425944182096\n",
      "Fail to reject null hypothesis: There is no significant difference between the means of two populations.\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Example data\n",
    "sample1 = [25, 30, 35, 40, 45]\n",
    "sample2 = [20, 28, 32, 38, 42]\n",
    "\n",
    "# Perform Z-test assuming variances are known and unequal\n",
    "t_statistic, p_value = stats.ttest_ind(sample1, sample2, equal_var=False)\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "print(\"T Statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"Reject null hypothesis: There is a significant difference between the means of two populations.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis: There is no significant difference between the means of two populations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fecea929-091f-4815-8817-9de65e23347d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score: 1.441153384245784\n",
      "P-value: 0.14954135458461515\n"
     ]
    }
   ],
   "source": [
    "group1 = np.array([75, 80, 85, 90, 95]) \n",
    "group2 = np.array([65, 70, 75, 80, 85, 90])  \n",
    "mean1 = np.mean(group1)  \n",
    "mean2 = np.mean(group2)  \n",
    "std1 = np.std(group1, ddof=1)  \n",
    "std2 = np.std(group2, ddof=1)  \n",
    "n1 = len(group1)  \n",
    "n2 = len(group2) \n",
    "\n",
    "z_score = (mean1 - mean2) / np.sqrt((std1**2 / n1) + (std2**2 / n2))\n",
    "\n",
    "p_value = 2 * (1 - ss.norm.cdf(abs(z_score)))\n",
    "\n",
    "print(\"Z-score:\", z_score)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c33c431-fdf5-4dcb-aaab-713cfea6cfa7",
   "metadata": {},
   "source": [
    "## Test 4 Z-test for a proportion (binomial distribution)\n",
    "\n",
    "Object\n",
    "To investigate the significance of the difference between an assumed proportion p0 and an observed proportion p\n",
    "\n",
    "$Z = \\frac{{p - p_0}}{{\\sqrt{\\frac{{p_0(1 - p_0)}}{{n}}}}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e66cfbe3-fa9d-44cc-861c-d87cf51469e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z Statistic: 0.8466675133346031\n",
      "P-value: 0.3971804712199202\n",
      "Reject null hypothesis: False\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# Sample data\n",
    "successes_sample1 = 25\n",
    "total_sample1 = 100\n",
    "successes_sample2 = 20\n",
    "total_sample2 = 100\n",
    "\n",
    "# Perform Z-test for proportions\n",
    "count = np.array([successes_sample1, successes_sample2])\n",
    "nobs = np.array([total_sample1, total_sample2])\n",
    "\n",
    "# Assuming null hypothesis of equal proportions\n",
    "z_stat, p_value = proportions_ztest(count, nobs)\n",
    "\n",
    "# Output results\n",
    "print(\"Z Statistic:\", z_stat)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Determine if the null hypothesis should be rejected\n",
    "alpha = 0.05\n",
    "reject_null = p_value < alpha\n",
    "print(\"Reject null hypothesis:\", reject_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef4b741-8bfd-4edd-80d4-eaddbcf9d0cf",
   "metadata": {},
   "source": [
    "## Test 5 Z-test for the equality of two proportions(binomial distribution)\n",
    "\n",
    "Object\n",
    "To investigate the assumption that the proportions π1 and π2 of elements from two populations are equal, based on two samples, one from each population.\n",
    "\n",
    "$Z = \\frac{(\\hat{p}_1 - \\hat{p}_2)}{\\sqrt{\\hat{p}(1-\\hat{p})\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83657b7c-751b-416e-98b1-8b2984a2db04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z Statistic: 1.4824986333222028\n",
      "P-value: 0.1382076669740257\n",
      "Fail to reject null hypothesis: There is no significant difference between the proportions.\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# Example data\n",
    "successes1 = 40  # Number of successes in sample 1\n",
    "trials1 = 100    # Number of trials in sample 1\n",
    "\n",
    "successes2 = 30  # Number of successes in sample 2\n",
    "trials2 = 100    # Number of trials in sample 2\n",
    "\n",
    "# Perform Z-test for two proportions\n",
    "z_stat, p_value = proportions_ztest([successes1, successes2], [trials1, trials2])\n",
    "\n",
    "# Print results\n",
    "print(\"Z Statistic:\", z_stat)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Interpret results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject null hypothesis: There is a significant difference between the proportions.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis: There is no significant difference between the proportions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "963d90d0-2eed-46d7-aaae-719bcde3ce4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-test statistic: -2.1239769762143657\n",
      "P-value: 0.033672068856345855\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "successes_group1 = 45  # Number of successes in group 1\n",
    "nobs_group1 = 100     # Total number of observations in group 1\n",
    "\n",
    "successes_group2 = 60  # Number of successes in group 2\n",
    "nobs_group2 = 100     # Total number of observations in group 2\n",
    "count = np.array([successes_group1, successes_group2])\n",
    "nobs = np.array([nobs_group1, nobs_group2])\n",
    "zstat, pval = sm.stats.proportions_ztest(count, nobs)\n",
    "\n",
    "# Output the test statistic and p-value\n",
    "print(\"Z-test statistic:\", zstat)\n",
    "print(\"P-value:\", pval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70881aaa-d9af-428c-9aa0-a0303bc7c4c8",
   "metadata": {},
   "source": [
    "## Test 6: Z-test for comparing two counts (Poisson distribution)\n",
    "\n",
    "Object\n",
    "To investigate the significance of the difference between two counts\n",
    "\n",
    "Let n1 and n2 be the two counts taken over times t1 and t2, respectively. Then the two\n",
    "average frequencies are R1 = n1/t1 and R2 = n2/t2. To test the assumption of equal\n",
    "average frequencies we use the test statistic\n",
    "$Z = \\frac{\\bar{R}_1 - \\bar{R}_2}{\\sqrt{\\frac{R_1}{t_1} + \\frac{R_2}{t_2}}}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33135cab-92c5-4a3d-856b-8db4d02668ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score: -7.071067811865475\n",
      "P-value: 1.5374597944280347e-12\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Define the counts for two samples\n",
    "count_sample1 = 50\n",
    "count_sample2 = 60\n",
    "\n",
    "# Calculate the means and standard deviations of the Poisson distributions\n",
    "mean1 = count_sample1\n",
    "mean2 = count_sample2\n",
    "std_dev1 = np.sqrt(count_sample1)\n",
    "std_dev2 = np.sqrt(count_sample2)\n",
    "\n",
    "# Calculate the pooled standard error\n",
    "pooled_std_error = np.sqrt((std_dev1**2 / count_sample1) + (std_dev2**2 / count_sample2))\n",
    "\n",
    "# Calculate the Z-score\n",
    "z_score = (mean1 - mean2) / pooled_std_error\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value = stats.norm.cdf(z_score)\n",
    "\n",
    "# Two-tailed test, so double the p-value\n",
    "p_value *= 2\n",
    "\n",
    "print(\"Z-score:\", z_score)\n",
    "print(\"P-value:\", p_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379d5e04-334e-43ea-a9ca-3e55543aab95",
   "metadata": {},
   "source": [
    "## Test 7 t-test for a population mean (variance unknown)\n",
    "Object\n",
    "To investigate the significance of the difference between an assumed population mean µ0 and a sample mean $\\overline{x}$\n",
    "\n",
    "$t = \\frac{\\bar{x} - \\mu}{s/\\sqrt{n}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a64d4297-fca5-4697-81ac-d9a5b56eea19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 0.3764233161298853\n",
      "P-value: 0.7093423019666218\n",
      "Fail to reject the null hypothesis. There is not enough evidence to suggest that the population mean is not 4.5\n"
     ]
    }
   ],
   "source": [
    "# Generate some sample data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "sample_data = np.random.normal(loc=5, scale=2, size=30)  # Sample data with mean 5 and std deviation 2\n",
    "\n",
    "# Define the population mean to test against\n",
    "pop_mean = 4.5\n",
    "\n",
    "# Perform t-test\n",
    "t_statistic, p_value = ss.ttest_1samp(sample_data, pop_mean)\n",
    "\n",
    "# Print results\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Determine significance\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. There is significant evidence to suggest that the population mean is not\", pop_mean)\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is not enough evidence to suggest that the population mean is not\", pop_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf375d-8d74-4310-975f-02afd3b020d9",
   "metadata": {},
   "source": [
    "## Test 8 t-test for two population means (variancesunknown but equal)\n",
    "Object:- To investigate the significance of the difference between the means of two populations\n",
    "\n",
    "$s_p^2 = \\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}$\n",
    "\n",
    "\n",
    "$t = \\frac{\\bar{X} - \\bar{Y}}{s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f3ea8ad-42fb-4f66-a78c-3333f22579df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: 1.9013318388714453\n",
      "P-Value: 0.07338999818575455\n",
      "Fail to reject the null hypothesis. There is no significant difference between the means.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data for two populations\n",
    "population1 = [17, 21, 26, 20, 19, 22, 18, 23, 25, 24]\n",
    "population2 = [16, 19, 23, 18, 17, 20, 15, 21, 22, 20]\n",
    "\n",
    "# Perform t-test assuming equal variances\n",
    "t_statistic, p_value = stats.ttest_ind(population1, population2, equal_var=True)\n",
    "\n",
    "# Print results\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"P-Value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. There is a significant difference between the means.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no significant difference between the means.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ffa858-9861-470a-837e-62a5f443be6a",
   "metadata": {},
   "source": [
    "## Test 9 t-test for two population means (variances unknown and unequal)\n",
    "\n",
    "Object:- To investigate the significance of the difference between the means of two populations.\n",
    "\n",
    "$t = \\frac{\\bar{X} - \\bar{Y}}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46700c91-e141-4443-8bbf-d265ffe938a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: 2.0\n",
      "p-value: 0.08051623795726257\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "x1 = [85, 90, 95, 100, 105]  # Sample data for population 1\n",
    "x2 = [75, 80, 85, 90, 95]     # Sample data for population 2\n",
    "\n",
    "t_statistic, p_value = stats.ttest_ind(x1, x2, equal_var=False)\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a132fa43-0f0d-41b8-8935-06da8b233ae0",
   "metadata": {},
   "source": [
    "## Test 10 t-test for two population means (method of paired comparisons)\n",
    "Object:-\n",
    "\n",
    "To investigate the significance of the difference between two population means, µ1 and µ2. No assumption is made about the population variances\n",
    "\n",
    "$t = \\frac{\\bar{d} - \\mu_0}{\\frac{s_d}{\\sqrt{n}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a12dc470-9abf-4337-b55c-68501c98dc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: 3.9999999999999996\n",
      "P-value: 0.016130089900092532\n",
      "Reject the null hypothesis. There is a significant difference between the means.\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Sample data for two groups\n",
    "group1 = [15, 16, 18, 20, 22]\n",
    "group2 = [14, 16, 17, 19, 21]\n",
    "\n",
    "# Perform paired t-test\n",
    "t_statistic, p_value = stats.ttest_rel(group1, group2)\n",
    "\n",
    "# Print the results\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. There is a significant difference between the means.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no significant difference between the means.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f81ae9-ca18-4e5e-9609-33066b2ed522",
   "metadata": {},
   "source": [
    "## Test 11 t-test of a regression coefficient\n",
    "Object\n",
    "To investigate the significance of the regression coefficient of y on x\n",
    "\n",
    "$t = \\frac{\\hat{\\beta} - \\beta_0}{\\text{SE}(\\hat{\\beta})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "151ca3be-fec7-45c7-86f6-ecb7af13d716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: inf\n",
      "p-value: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marat\\AppData\\Local\\Temp\\ipykernel_7032\\2237107004.py:19: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  t_statistic = slope / slope_std_err\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Example data\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([2, 3, 4, 5, 6])\n",
    "\n",
    "# Perform linear regression to get the coefficients\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "# Calculate standard error of the slope\n",
    "n = len(x)\n",
    "df = n - 2  # degrees of freedom\n",
    "residuals = y - (slope * x + intercept)\n",
    "residual_std_err = np.sqrt(np.sum(residuals ** 2) / df)\n",
    "slope_std_err = residual_std_err / np.sqrt(np.sum((x - np.mean(x)) ** 2))\n",
    "\n",
    "# Calculate t-statistic\n",
    "t_statistic = slope / slope_std_err\n",
    "\n",
    "# Calculate p-value\n",
    "p_value = stats.t.sf(np.abs(t_statistic), df) * 2  # two-sided test\n",
    "\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b84e87-ca87-4c57-a486-65703a1685f4",
   "metadata": {},
   "source": [
    "## Test 12 t-test of a correlation coefficient\n",
    "Object\n",
    "To investigate whether the difference between the sample correlation coefficient and zero is statistically significant\n",
    "\n",
    "$t = \\frac{r \\sqrt{n - 2}}{\\sqrt{1 - r^2}}$\n",
    "\n",
    "where $r = \\frac{{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}}{{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2 \\sum_{i=1}^{n} (y_i - \\bar{y})^2}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e0873ac-8c6e-41f2-a8b6-755c914a29df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-value: 5.196152422706631\n",
      "p-value: 4.120215931102678e-06\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "\n",
    "def correlation_t_test(r, n):\n",
    "    df = n - 2  # degrees of freedom\n",
    "    t_value = r * np.sqrt(df) / np.sqrt(1 - r**2)\n",
    "    p_value = 2 * (1 - t.cdf(abs(t_value), df))\n",
    "    return t_value, p_value\n",
    "\n",
    "# Example usage:\n",
    "r = 0.6  # correlation coefficient\n",
    "n = 50   # number of samples\n",
    "t_value, p_value = correlation_t_test(r, n)\n",
    "print(\"t-value:\", t_value)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4873988-d911-4de7-a01a-b6972d1b81b7",
   "metadata": {},
   "source": [
    "## Test 13 Z-test of a correlation coefficient\n",
    "Object\n",
    "To investigate the significance of the difference between a correlation coefficient and a specified value ρ0\n",
    "\n",
    "$Z = \\frac{1}{2} \\ln\\left(\\frac{{1+r}}{{1-r}}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ac3886d-c56d-4473-abcd-47099e3f9cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score: 6.670243932669069\n",
      "P-value: 2.55377941016377e-11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def z_test_correlation(r, n):\n",
    "\n",
    "    # Calculate the Z-score using Fisher's transformation\n",
    "    z_score = 0.5 * np.log((1 + r) / (1 - r)) * np.sqrt(n - 3)\n",
    "\n",
    "    # Calculate the p-value\n",
    "    p_value = 2 * (1 - ss.norm.cdf(abs(z_score)))\n",
    "\n",
    "    return z_score, p_value\n",
    "\n",
    "# Example usage:\n",
    "# Sample correlation coefficient\n",
    "r = 0.75\n",
    "# Sample size\n",
    "n = 50\n",
    "\n",
    "# Perform Z-test\n",
    "z_score, p_value = z_test_correlation(r, n)\n",
    "\n",
    "print(\"Z-score:\", z_score)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a8a096-ae78-4e9d-9dad-622e52af61a9",
   "metadata": {},
   "source": [
    "## Test 15   χ2-test for a population variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90551c80-52eb-4efc-95f5-4037eac02923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square Statistic: 1.583333333333333\n",
      "Critical Value: 9.487729036781154\n",
      "Reject null hypothesis: False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def chi_square_test_population_variance(sample, sigma_squared, alpha):\n",
    "    n = len(sample)\n",
    "    sample_variance = np.var(sample, ddof=1)  # Sample variance\n",
    "    \n",
    "    # Calculate the test statistic\n",
    "    chi2_statistic = (n - 1) * sample_variance / sigma_squared\n",
    "    \n",
    "    # Calculate the critical value\n",
    "    critical_value = chi2.ppf(1 - alpha, df=n - 1)\n",
    "    \n",
    "    # Determine if the null hypothesis should be rejected\n",
    "    reject_null = chi2_statistic > critical_value\n",
    "    \n",
    "    return chi2_statistic, critical_value, reject_null\n",
    "\n",
    "# Example usage:\n",
    "sample = [3.2, 4.5, 2.8, 3.9, 4.1]\n",
    "sigma_squared = 1.2\n",
    "alpha = 0.05\n",
    "chi2_statistic, critical_value, reject_null = chi_square_test_population_variance(sample, sigma_squared, alpha)\n",
    "\n",
    "print(\"Chi-square Statistic:\", chi2_statistic)\n",
    "print(\"Critical Value:\", critical_value)\n",
    "print(\"Reject null hypothesis:\", reject_null)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b511bea-593b-47d5-a399-4d706506a537",
   "metadata": {},
   "source": [
    "## Test 16 F-test for two population variances (variance ratio test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4eb09a95-d233-4cf3-8060-ad1c1486e093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F Statistic: 0.32967032967032966\n",
      "P-value: 0.5816333668955771\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Example datasets\n",
    "sample1 = [25, 30, 35, 40, 45]\n",
    "sample2 = [20, 28, 32, 38, 42]\n",
    "\n",
    "# Perform F-test\n",
    "f_statistic, p_value = stats.f_oneway(sample1, sample2)\n",
    "\n",
    "# Print results\n",
    "print(\"F Statistic:\", f_statistic)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7967ca2e-b5c9-4f94-ac51-ddf438946f50",
   "metadata": {},
   "source": [
    "## Test 17 F-test for two population variances (with correlated observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a256649-8cd2-4c18-a6e2-8a6e046c9abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 0.3932327586206897\n",
      "p-value: 0.8059820108967887\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "def f_test_correlated(X, Y):\n",
    "    \n",
    "\n",
    "    n1 = len(X)\n",
    "    n2 = len(Y)\n",
    "    dof1 = n1 - 1\n",
    "    dof2 = n2 - 1\n",
    "\n",
    "    # Compute the means\n",
    "    mean_X = np.mean(X)\n",
    "    mean_Y = np.mean(Y)\n",
    "\n",
    "    # Compute the squared deviations from the mean\n",
    "    Sx = np.sum((X - mean_X) ** 2)\n",
    "    Sy = np.sum((Y - mean_Y) ** 2)\n",
    "\n",
    "    # Compute the squared deviations from the individual means\n",
    "    Sxy = np.sum((X - mean_X) * (Y - mean_Y))\n",
    "\n",
    "    # Compute the F-statistic\n",
    "    F_statistic = (Sy / dof2) / (Sx / dof1)\n",
    "\n",
    "    # Compute the p-value\n",
    "    p_value = f.sf(F_statistic, dof2, dof1)\n",
    "\n",
    "    return F_statistic, p_value\n",
    "\n",
    "# Example usage:\n",
    "X = np.array([10, 122, 14, 16, 18])\n",
    "Y = np.array([141, 123, 185, 174, 194])\n",
    "\n",
    "F_statistic, p_value = f_test_correlated(X, Y)\n",
    "print(\"F-statistic:\", F_statistic)0\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a177b77-621c-489a-9458-cbfd41ed63ec",
   "metadata": {},
   "source": [
    "## Test 18 Hotelling’s T2-test for two series of population means\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bb3b99-316a-4582-a0f7-24ddd5b90030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "def hotelling_t2_test(sample1, sample2):\n",
    "    n1, n2 = len(sample1), len(sample2)\n",
    "    p = len(sample1[0])  # Assuming both samples have the same number of features\n",
    "    \n",
    "    mean1 = np.mean(sample1, axis=0)\n",
    "    mean2 = np.mean(sample2, axis=0)\n",
    "    \n",
    "    cov1 = np.cov(sample1, rowvar=False)\n",
    "    cov2 = np.cov(sample2, rowvar=False)\n",
    "    \n",
    "    s_pooled = ((n1 - 1) * cov1 + (n2 - 1) * cov2) / (n1 + n2 - 2)\n",
    "    \n",
    "    t_squared = (n1 * n2) / (n1 + n2) * np.dot(np.dot((mean1 - mean2).T, np.linalg.inv(s_pooled)), (mean1 - mean2))\n",
    "    \n",
    "    df1 = p\n",
    "    df2 = n1 + n2 - p - 1\n",
    "    \n",
    "    F = (df2 / (df1 * (df2 - 2))) * t_squared\n",
    "    p_value = 1 - f.cdf(F, df1, df2)\n",
    "    \n",
    "    return t_squared, p_value\n",
    "\n",
    "# Example usage:\n",
    "sample1 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])  # First sample\n",
    "sample2 = np.array([[2, 3, 4], [5, 6, 7], [8, 9, 10]])  # Second sample\n",
    "\n",
    "t_squared, p_value = hotelling_t2_test(sample1, sample2)\n",
    "print(\"Hotelling's T^2 statistic:\", t_squared)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346ee6c6-128f-490f-a61a-eeedc63fd1b1",
   "metadata": {},
   "source": [
    "## Test 19 Discriminant test for the origin of a p-fold sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fd2c4bd-2956-42e9-8517-5fbad309a957",
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m], [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m], [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]])  \u001b[38;5;66;03m# Sample data of shape (n, p)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# Dimensionality\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminant_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "Cell \u001b[1;32mIn[5], line 28\u001b[0m, in \u001b[0;36mdiscriminant_test\u001b[1;34m(data, p)\u001b[0m\n\u001b[0;32m     24\u001b[0m within_class_scatter \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m n\n\u001b[0;32m     26\u001b[0m between_class_scatter \u001b[38;5;241m=\u001b[39m cov_matrix \u001b[38;5;241m-\u001b[39m within_class_scatter\n\u001b[1;32m---> 28\u001b[0m eigenvalues, _ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39meig(np\u001b[38;5;241m.\u001b[39mdot(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwithin_class_scatter\u001b[49m\u001b[43m)\u001b[49m, between_class_scatter))\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(eigenvalues \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe origin is not in the convex hull of the sample points.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mC:\\python123\\Lib\\site-packages\\numpy\\linalg\\linalg.py:561\u001b[0m, in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    559\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    560\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[1;32m--> 561\u001b[0m ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[1;32mC:\\python123\\Lib\\site-packages\\numpy\\linalg\\linalg.py:112\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def discriminant_test(data, p):\n",
    "    n = data.shape[0]\n",
    "    mean_vector = np.mean(data, axis=0)\n",
    "    cov_matrix = np.cov(data, rowvar=False)\n",
    "\n",
    "    within_class_scatter = np.zeros((p, p))\n",
    "    for i in range(n):\n",
    "        xi = data[i, :].reshape(p, 1)\n",
    "        mean_i = mean_vector.reshape(p, 1)\n",
    "        within_class_scatter += np.dot((xi - mean_i), (xi - mean_i).T)\n",
    "\n",
    "    within_class_scatter /= n\n",
    "\n",
    "    between_class_scatter = cov_matrix - within_class_scatter\n",
    "\n",
    "    eigenvalues, _ = np.linalg.eig(np.dot(np.linalg.inv(within_class_scatter), between_class_scatter))\n",
    "\n",
    "    if np.all(eigenvalues > 0):\n",
    "        return \"The origin is not in the convex hull of the sample points.\"\n",
    "    else:\n",
    "        return \"The origin is in the convex hull of the sample points.\"\n",
    "\n",
    "# Example usage:\n",
    "data = np.array([[1, 2], [3, 4], [5, 6]])  # Sample data of shape (n, p)\n",
    "p = 2  # Dimensionality\n",
    "result = discriminant_test(data, p)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67803e04-e8a2-419f-8afa-17270326cf73",
   "metadata": {},
   "source": [
    "## Test 20 Fisher’s cumulant test for normality of a population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17d5f91f-1857-405d-ab31-09737fc6e6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The null hypothesis of normality cannot be rejected.\n",
      "Test statistic: 0.07633332061456478\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def fisher_cumulant_test(data):\n",
    "    n = len(data)\n",
    "    x_bar = np.mean(data)\n",
    "    s2 = np.var(data, ddof=1)\n",
    "    \n",
    "    k2 = sum((data - x_bar)**4) / (n * s2**2) - 3\n",
    "    k3 = sum((data - x_bar)**6) / (n * s2**3) - 15\n",
    "    \n",
    "    # Calculate test statistic\n",
    "    W = k2**2 / 24 + k3**2 / 1440\n",
    "    \n",
    "    # Calculate critical value from chi-square distribution\n",
    "    chi_critical = norm.ppf(0.95)\n",
    "    \n",
    "    # Perform hypothesis test\n",
    "    if W < chi_critical:\n",
    "        print(\"The null hypothesis of normality cannot be rejected.\")\n",
    "    else:\n",
    "        print(\"The null hypothesis of normality is rejected.\")\n",
    "    \n",
    "    return W\n",
    "\n",
    "# Example usage:\n",
    "data = np.random.normal(loc=0, scale=1, size=100)\n",
    "W = fisher_cumulant_test(data)\n",
    "print(\"Test statistic:\", W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3991d3-29ea-4ca7-ba28-4bbd83eaf8f0",
   "metadata": {},
   "source": [
    "## Test 21 Dixon’s test for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce106d7-3f38-4110-9f84-c0b9e1081184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper outlier: 2.47\n",
      "Lower outlier: 2.34\n"
     ]
    }
   ],
   "source": [
    "def dixons_test(data, test_type='upper', alpha=0.05):\n",
    "    \"\"\"\n",
    "    Perform Dixon's test for outliers.\n",
    "    \n",
    "    Parameters:\n",
    "        data (list or numpy array): The dataset.\n",
    "        test_type (str): The type of test to perform. Either 'upper' or 'lower'.\n",
    "        alpha (float): The significance level.\n",
    "        \n",
    "    Returns:\n",
    "        outlier (float): The identified outlier value, or None if no outlier is found.\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    data_sorted = sorted(data)\n",
    "    \n",
    "    if test_type == 'upper':\n",
    "        ratio = (data_sorted[-1] - data_sorted[-2]) / (data_sorted[-1] - data_sorted[0])\n",
    "        critical_value = 0.289 if n <= 10 else 0.269 / n**0.5\n",
    "        outlier = data_sorted[-1] if ratio > critical_value else None\n",
    "    elif test_type == 'lower':\n",
    "        ratio = (data_sorted[1] - data_sorted[0]) / (data_sorted[-1] - data_sorted[0])\n",
    "        critical_value = 0.289 if n <= 10 else 0.269 / n**0.5\n",
    "        outlier = data_sorted[0] if ratio > critical_value else None\n",
    "    else:\n",
    "        raise ValueError(\"Invalid test_type. Choose either 'upper' or 'lower'.\")\n",
    "        \n",
    "    return outlier if outlier is not None and outlier > alpha else None\n",
    "\n",
    "# Example usage:\n",
    "data = [2.34, 2.36, 2.37, 2.37, 2.37, 2.38, 2.39, 2.40, 2.40, 2.41, 2.41, 2.42, 2.42, 2.43, 2.43, 2.44, 2.45, 2.47]\n",
    "outlier_upper = dixons_test(data, test_type='upper')\n",
    "outlier_lower = dixons_test(data, test_type='lower')\n",
    "\n",
    "print(\"Upper outlier:\", outlier_upper)\n",
    "print(\"Lower outlier:\", outlier_lower)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22d6d91-36e6-49dc-b434-5759aa957e5f",
   "metadata": {},
   "source": [
    "## Test 22 F-test for K population means (analysis of variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ccbdbfc-6140-4dfc-8887-85dd0441d750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 35.58222222222222\n",
      "p-value: 9.025293462715861e-06\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def f_test(*args):\n",
    "    # Calculate the total number of samples and total number of groups\n",
    "    N = sum(len(group) for group in args)\n",
    "    k = len(args)\n",
    "    \n",
    "    # Calculate the grand mean\n",
    "    grand_mean = np.mean(np.concatenate(args))\n",
    "    \n",
    "    # Calculate the between-group sum of squares (SSB)\n",
    "    SSB = sum(len(group) * (np.mean(group) - grand_mean)**2 for group in args)\n",
    "    \n",
    "    # Calculate the degrees of freedom for between-group variation\n",
    "    df_between = k - 1\n",
    "    \n",
    "    # Calculate the within-group sum of squares (SSW)\n",
    "    SSW = sum(np.var(group, ddof=1) * (len(group) - 1) for group in args)\n",
    "    \n",
    "    # Calculate the degrees of freedom for within-group variation\n",
    "    df_within = N - k\n",
    "    \n",
    "    # Calculate the F-statistic\n",
    "    F = (SSB / df_between) / (SSW / df_within)\n",
    "    \n",
    "    # Calculate the p-value\n",
    "    p_value = stats.f.sf(F, df_between, df_within)\n",
    "    \n",
    "    return F, p_value\n",
    "\n",
    "# Example usage:\n",
    "group1 = [15, 12, 18, 16, 19]\n",
    "group2 = [22, 20, 25, 28, 24]\n",
    "group3 = [30, 32, 28, 34, 29]\n",
    "\n",
    "F, p_value = f_test(group1, group2, group3)\n",
    "\n",
    "print(\"F-statistic:\", F)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c321db-2453-48fc-aa3a-4ed5296cab8e",
   "metadata": {},
   "source": [
    "## Test 23 The Z-test for correlated proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afb90f64-b5a9-4e86-82e7-3616a9e4e084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score: 1.912216662712981\n",
      "P-value: 0.055848409746675154\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def z_test_correlated_proportions(n1, p1, n2, p2, rho):\n",
    "    # Calculate pooled proportion\n",
    "    p_pool = (n1 * p1 + n2 * p2) / (n1 + n2)\n",
    "    \n",
    "    # Calculate standard error\n",
    "    se = np.sqrt((p_pool * (1 - p_pool)) * ((1/n1) + (1/n2) - (2 * rho / (np.sqrt(n1 * n2)))))\n",
    "    \n",
    "    # Calculate z-score\n",
    "    z_score = (p1 - p2) / se\n",
    "    \n",
    "    # Calculate p-value\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))  # two-tailed test\n",
    "    \n",
    "    return z_score, p_value\n",
    "\n",
    "# Example usage\n",
    "n1 = 100  # Sample size for group 1\n",
    "p1 = 0.6  # Proportion for group 1\n",
    "n2 = 120  # Sample size for group 2\n",
    "p2 = 0.5  # Proportion for group 2\n",
    "rho = 0.4  # Correlation coefficient\n",
    "\n",
    "z_score, p_value = z_test_correlated_proportions(n1, p1, n2, p2, rho)\n",
    "print(\"Z-score:\", z_score)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c355ca3c-9713-4d06-a301-6dcbf3fa635e",
   "metadata": {},
   "source": [
    "## Test 24 χ2-test for an assumed population variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abfeabf1-6ad3-431f-80e1-65b3245ac81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared value: 5.0\n",
      "P-value: 0.2872974951836458\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def chi2_test(data, sigma_sq):\n",
    "    n = len(data)\n",
    "    sample_variance = np.var(data, ddof=1)  # Sample variance\n",
    "    chi_squared = (n - 1) * sample_variance / sigma_sq\n",
    "    p_value = 1 - chi2.cdf(chi_squared, df=n - 1)\n",
    "    return chi_squared, p_value\n",
    "\n",
    "# Example usage:\n",
    "data = [10, 15, 20, 25, 30]  # Sample data\n",
    "assumed_variance = 50  # Assumed population variance\n",
    "\n",
    "chi_squared, p_value = chi2_test(data, assumed_variance)\n",
    "print(\"Chi-squared value:\", chi_squared)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0981da-2ad9-42d2-b22d-6733c770a97a",
   "metadata": {},
   "source": [
    "## Test 25 F-test for two counts (Poisson distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdb2cd45-936e-43ba-98ee-83c94b1577b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 1.9799387129724209\n",
      "p-value: 0.9996069026679197\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "def f_test_poisson(counts1, counts2):\n",
    "    \"\"\"\n",
    "    Perform F-test for two Poisson-distributed count variables.\n",
    "    \n",
    "    Parameters:\n",
    "        counts1 (array-like): Counts for sample 1.\n",
    "        counts2 (array-like): Counts for sample 2.\n",
    "        \n",
    "    Returns:\n",
    "        f_statistic (float): F-statistic.\n",
    "        p_value (float): p-value.\n",
    "    \"\"\"\n",
    "    # Compute means and variances for each sample\n",
    "    mean1 = np.mean(counts1)\n",
    "    mean2 = np.mean(counts2)\n",
    "    var1 = np.var(counts1)\n",
    "    var2 = np.var(counts2)\n",
    "    \n",
    "    # Calculate F-statistic\n",
    "    f_statistic = var1 / var2 if var1 > var2 else var2 / var1\n",
    "    \n",
    "    # Degrees of freedom\n",
    "    df1 = len(counts1) - 1\n",
    "    df2 = len(counts2) - 1\n",
    "    \n",
    "    # Calculate p-value\n",
    "    p_value = f.cdf(f_statistic, df1, df2)\n",
    "    \n",
    "    return f_statistic, p_value\n",
    "\n",
    "# Example usage\n",
    "counts1 = np.random.poisson(3, 100)  # Sample 1 with mean lambda = 3\n",
    "counts2 = np.random.poisson(4, 100)  # Sample 2 with mean lambda = 4\n",
    "\n",
    "f_statistic, p_value = f_test_poisson(counts1, counts2)\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95047a22-1442-4fa1-a92a-4b88add18d83",
   "metadata": {},
   "source": [
    "## Test 26 F-test for the overall mean of K subpopulations (analysis of variance)\n",
    "\n",
    "\n",
    "$F = \\frac{{s_1^2 / (k - 1)}}{{s_2^2 / (N - k)}}$\n",
    "\n",
    "where  $s_{1}^{2} = \\sum_{j} n_{j} \\cdot (x_{.j} - {x..})^{2}$\n",
    "\n",
    "$s_{2}^{2}=\\sum_{i}\\sum_{j}(x_{ij}-\\bar{x}_{.j})^{2}$\n",
    "\n",
    "${i}=1,2.....{n_j}$    \n",
    "${j}=1,2.....{k}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eb780af-feb1-4e44-9176-ed19bc159a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 4.666666666666667\n",
      "p-value: 0.031676352024078334\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "def f_test(*args):\n",
    "    \"\"\"\n",
    "    Perform F-test (one-way ANOVA) for the overall mean of K subpopulations.\n",
    "    \n",
    "    Parameters:\n",
    "    *args: array-like\n",
    "        Arrays containing the observations for each group.\n",
    "        \n",
    "    Returns:\n",
    "    F-statistic: float\n",
    "        The computed F-statistic.\n",
    "    p-value: float\n",
    "        The associated p-value for the test.\n",
    "    \"\"\"\n",
    "    # Calculate the number of groups\n",
    "    k = len(args)\n",
    "    \n",
    "    # Calculate the total number of observations\n",
    "    n = sum(len(group) for group in args)\n",
    "    \n",
    "    # Calculate the overall mean\n",
    "    grand_mean = np.mean(np.concatenate(args))\n",
    "    \n",
    "    # Calculate the between-group sum of squares (SSB)\n",
    "    ssb = sum(len(group) * (np.mean(group) - grand_mean)**2 for group in args)\n",
    "    \n",
    "    # Calculate the within-group sum of squares (SSW)\n",
    "    ssw = sum(sum((x - np.mean(group))**2 for x in group) for group in args)\n",
    "    \n",
    "    # Calculate the degrees of freedom\n",
    "    df_between = k - 1\n",
    "    df_within = n - k\n",
    "    \n",
    "    # Calculate the mean square for between-groups (MSB) and within-groups (MSW)\n",
    "    msb = ssb / df_between\n",
    "    msw = ssw / df_within\n",
    "    \n",
    "    # Calculate the F-statistic\n",
    "    f_statistic = msb / msw\n",
    "    \n",
    "    # Calculate the p-value\n",
    "    p_value = f.sf(f_statistic, df_between, df_within)\n",
    "    \n",
    "    return f_statistic, p_value\n",
    "\n",
    "# Example usage:\n",
    "group1 = [15, 20, 25, 30, 35]\n",
    "group2 = [10, 15, 20, 25, 30]\n",
    "group3 = [25, 30, 35, 40, 45]\n",
    "\n",
    "f_stat, p_val = f_test(group1, group2, group3)\n",
    "print(\"F-statistic:\", f_stat)\n",
    "print(\"p-value:\", p_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630004e0-4168-4dd6-9b8c-5c714d4b7e19",
   "metadata": {},
   "source": [
    "## Test 27 F-test for multiple comparison of contrasts between K population means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e85fd40-bf87-4f2c-81de-a461354d9dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-value: [[ 10. -20.  inf]\n",
      " [-20.  10. -20.]\n",
      " [ inf -20.  10.]]\n",
      "p-value: [[0.00235158 1.         0.        ]\n",
      " [1.         0.00235158 1.        ]\n",
      " [0.         1.         0.00235158]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marat\\AppData\\Local\\Temp\\ipykernel_2276\\183630968.py:24: RuntimeWarning: divide by zero encountered in divide\n",
      "  f_value = (contrast_means.T @ contrast_means / df_contrast) / (contrast_variance / df_residuals)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "def f_test(contrast_matrix, residuals, df_contrast, df_residuals):\n",
    "    \"\"\"\n",
    "    Performs F-test for multiple comparison of contrasts between K population means.\n",
    "\n",
    "    Parameters:\n",
    "        contrast_matrix (array-like): Contrast matrix for the linear combination of means.\n",
    "        residuals (array-like): Residuals from the ANOVA model.\n",
    "        df_contrast (int): Degrees of freedom for the contrast.\n",
    "        df_residuals (int): Degrees of freedom for the residuals.\n",
    "\n",
    "    Returns:\n",
    "        f_value (float): The computed F-value.\n",
    "        p_value (float): The corresponding p-value.\n",
    "    \"\"\"\n",
    "    contrast_matrix = np.array(contrast_matrix)\n",
    "    residuals = np.array(residuals)\n",
    "    \n",
    "    contrast_means = contrast_matrix @ residuals\n",
    "    mse = sum(residuals ** 2) / df_residuals\n",
    "    contrast_variance = np.dot(contrast_matrix, np.dot(contrast_matrix.T, mse))\n",
    "    f_value = (contrast_means.T @ contrast_means / df_contrast) / (contrast_variance / df_residuals)\n",
    "    p_value = 1 - f.cdf(f_value, df_contrast, df_residuals)\n",
    "    return f_value, p_value\n",
    "\n",
    "# Example usage\n",
    "contrast_matrix = [[1, -1, 0, 0], [0, 1, -1, 0], [0, 0, 1, -1]]\n",
    "residuals = [2, 1, -1, -2]  # Example residuals from ANOVA\n",
    "df_contrast = 3  # Degrees of freedom for the contrast\n",
    "df_residuals = 10  # Degrees of freedom for the residuals\n",
    "\n",
    "f_value, p_value = f_test(contrast_matrix, residuals, df_contrast, df_residuals)\n",
    "print(\"F-value:\", f_value)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4bb2bcf-1260-4cde-85f6-1f96ba9f23ac",
   "metadata": {},
   "source": [
    "## Test 28 Tukey test for multiple comparison of K population means (unequal sample sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40a7bb80-e924-47fb-a16e-703404a3d823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "=====================================================\n",
      " group1  group2 meandiff p-adj   lower  upper  reject\n",
      "-----------------------------------------------------\n",
      "Group 1 Group 2   2.4002 0.0007  0.9114 3.8889   True\n",
      "Group 1 Group 3   1.8222 0.0058  0.4545   3.19   True\n",
      "Group 2 Group 3  -0.5779 0.6057 -2.0175 0.8617  False\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.stats.multicomp as mc\n",
    "\n",
    "# Example data (replace with your own data)\n",
    "group1 = np.random.normal(loc=10, scale=2, size=30)\n",
    "group2 = np.random.normal(loc=12, scale=2.5, size=25)\n",
    "group3 = np.random.normal(loc=11, scale=2.2, size=35)\n",
    "\n",
    "# Concatenate data\n",
    "data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Create group labels\n",
    "groups = ['Group 1'] * len(group1) + ['Group 2'] * len(group2) + ['Group 3'] * len(group3)\n",
    "\n",
    "# Perform Tukey's HSD test\n",
    "tukey_results = mc.MultiComparison(data, groups).tukeyhsd()\n",
    "\n",
    "# Print results\n",
    "print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad02c182-0da8-40f0-a959-e49fe1c6480a",
   "metadata": {},
   "source": [
    "## Test 29 The Link–Wallace test for multiple comparison of K population means (equal sample sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2604ba89-9137-41e8-b00e-3bbfc4ced4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 11.292929292929296\n",
      "p-value: 0.0017446009628989678\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "def link_wallace_test(*args):\n",
    "    # Number of groups\n",
    "    k = len(args)\n",
    "    \n",
    "    # Number of observations per group\n",
    "    n = len(args[0])\n",
    "    \n",
    "    # Calculate overall mean\n",
    "    grand_mean = np.mean(np.concatenate(args))\n",
    "    \n",
    "    # Calculate sum of squares between groups\n",
    "    ss_between = 0\n",
    "    for group in args:\n",
    "        ss_between += len(group) * (np.mean(group) - grand_mean)**2\n",
    "    \n",
    "    # Calculate sum of squares within groups\n",
    "    ss_within = 0\n",
    "    for group in args:\n",
    "        ss_within += np.sum((group - np.mean(group))**2)\n",
    "    \n",
    "    # Calculate degrees of freedom\n",
    "    df_between = k - 1\n",
    "    df_within = k * (n - 1)\n",
    "    \n",
    "    # Calculate mean square between\n",
    "    ms_between = ss_between / df_between\n",
    "    \n",
    "    # Calculate mean square within\n",
    "    ms_within = ss_within / df_within\n",
    "    \n",
    "    # Calculate F-statistic\n",
    "    f_statistic = ms_between / ms_within\n",
    "    \n",
    "    # Calculate p-value\n",
    "    p_value = 1 - f.cdf(f_statistic, df_between, df_within)\n",
    "    \n",
    "    return f_statistic, p_value\n",
    "\n",
    "# Example usage\n",
    "group1 = np.array([87, 91, 93, 88, 82])\n",
    "group2 = np.array([79, 84, 83, 80, 78])\n",
    "group3 = np.array([91, 86, 90, 89, 92])\n",
    "\n",
    "f_statistic, p_value = link_wallace_test(group1, group2, group3)\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e2a222-ea47-446d-a4d3-5003c3fc9505",
   "metadata": {},
   "source": [
    "## Test 30 Dunnett’s test for comparing K treatments with a control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82f97a10-090a-42ef-9ebb-138401ef4a8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "data has 3 elements and groups has 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m treatment_values \u001b[38;5;241m=\u001b[39m data[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTreatment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m control_treatment][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValues\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Perform Dunnett's test\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m multi_comp \u001b[38;5;241m=\u001b[39m \u001b[43mMultiComparison\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtreatment_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m result \u001b[38;5;241m=\u001b[39m multi_comp\u001b[38;5;241m.\u001b[39mtukeyhsd()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Print the summary of the test\u001b[39;00m\n",
      "File \u001b[1;32mC:\\python123\\Lib\\site-packages\\statsmodels\\sandbox\\stats\\multicomp.py:811\u001b[0m, in \u001b[0;36mMultiComparison.__init__\u001b[1;34m(self, data, groups, group_order)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, groups, group_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(groups):\n\u001b[1;32m--> 811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata has \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m elements and groups has \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(data), \u001b[38;5;28mlen\u001b[39m(groups)))\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data)\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups \u001b[38;5;241m=\u001b[39m groups \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(groups)\n",
      "\u001b[1;31mValueError\u001b[0m: data has 3 elements and groups has 1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "# Example data\n",
    "data = pd.DataFrame({\n",
    "    'Treatment': ['Control', 'A', 'B', 'C'],\n",
    "    'Values': [10, 15, 18, 14]  # Sample values for each treatment\n",
    "})\n",
    "\n",
    "# Define control treatment\n",
    "control_treatment = 'Control'\n",
    "\n",
    "# Extract control and treatment values\n",
    "control_values = data[data['Treatment'] == control_treatment]['Values']\n",
    "treatment_values = data[data['Treatment'] != control_treatment]['Values']\n",
    "\n",
    "# Perform Dunnett's test\n",
    "multi_comp = MultiComparison(treatment_values, control_values)\n",
    "result = multi_comp.tukeyhsd()\n",
    "\n",
    "# Print the summary of the test\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dede89-2a8a-4389-84ac-bdbbf9c7d9cb",
   "metadata": {},
   "source": [
    "## Test 31 Bartlett’s test for equality of K variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67349fa7-8d56-47a9-99b2-f3c243a2a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def bartlett_test(*args):\n",
    "    \"\"\"\n",
    "    Perform Bartlett's test for equality of variances.\n",
    "    \n",
    "    Parameters:\n",
    "    *args: sequences of sample data for each group\n",
    "    \n",
    "    Returns:\n",
    "    statistic: the test statistic\n",
    "    p_value: the p-value of the test\n",
    "    \"\"\"\n",
    "    try:\n",
    "        stat, p_value = stats.bartlett(*args)\n",
    "        return stat, p_value\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "# Example usage:\n",
    "# data_group1, data_group2, data_group3 = [list_of_data_for_each_group]\n",
    "# stat, p_value = bartlett_test(data_group1, data_group2, data_group3)\n",
    "# print(\"Test statistic:\", stat)\n",
    "# print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dd88b0-5631-422c-b46d-4ba4186819c5",
   "metadata": {},
   "source": [
    "## Test 32 Hartley’s test for equality of K variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d641cfd5-f703-4e08-99cc-4692e6d01e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hartley's F-statistic: 0.9230769230769232\n",
      "p-value: 0.4237527791495198\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "def hartley_test(*args):\n",
    "    \"\"\"\n",
    "    Hartley's test for equality of variances.\n",
    "    \n",
    "    Parameters:\n",
    "    args : sequence of array-like\n",
    "        Arrays containing the data for each group.\n",
    "        \n",
    "    Returns:\n",
    "    F_statistic : float\n",
    "        The computed F-statistic.\n",
    "    p_value : float\n",
    "        The p-value associated with the F-statistic.\n",
    "    \"\"\"\n",
    "    num_groups = len(args)\n",
    "    group_sizes = [len(group) for group in args]\n",
    "    \n",
    "    if len(set(group_sizes)) != 1:\n",
    "        raise ValueError(\"All groups must have the same number of observations.\")\n",
    "    \n",
    "    num_obs = group_sizes[0]\n",
    "    \n",
    "    # Compute the variance for each group\n",
    "    variances = [np.var(group, ddof=1) for group in args]\n",
    "    \n",
    "    # Compute the total variance\n",
    "    total_variance = np.var(np.concatenate(args), ddof=num_groups)\n",
    "    \n",
    "    # Compute the Hartley's F-statistic\n",
    "    F_statistic = max(variances) / total_variance\n",
    "    \n",
    "    # Compute the degrees of freedom for the numerator and denominator\n",
    "    df_between = num_groups - 1\n",
    "    df_within = num_groups * (num_obs - 1)\n",
    "    \n",
    "    # Compute the p-value using the F-distribution\n",
    "    p_value = 1 - f.cdf(F_statistic, df_between, df_within)\n",
    "    \n",
    "    return F_statistic, p_value\n",
    "\n",
    "# Example usage:\n",
    "group1 = np.array([1.2, 1.4, 1.6, 1.8, 2.0])\n",
    "group2 = np.array([1.1, 1.3, 1.5, 1.7, 1.9])\n",
    "group3 = np.array([1.0, 1.2, 1.4, 1.6, 1.8])\n",
    "\n",
    "F_statistic, p_value = hartley_test(group1, group2, group3)\n",
    "print(\"Hartley's F-statistic:\", F_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4b631a-687f-4b4b-8962-e3b14cb8fc40",
   "metadata": {},
   "source": [
    "## Test 33 The w/s-test for normality of a population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00d522a1-4e87-4963-9062-2169b7b8d30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro-Wilk Test Statistic: 0.8951008586832423\n",
      "p-value: 0.19340863556472415\n",
      "Sample looks Gaussian (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "# Your data\n",
    "data = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\n",
    "\n",
    "# Perform Shapiro-Wilk test\n",
    "statistic, p_value = shapiro(data)\n",
    "\n",
    "# Print the results\n",
    "print(\"Shapiro-Wilk Test Statistic:\", statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check the normality\n",
    "alpha = 0.05\n",
    "if p_value > alpha:\n",
    "    print(\"Sample looks Gaussian (fail to reject H0)\")\n",
    "else:\n",
    "    print(\"Sample does not look Gaussian (reject H0)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86d6d2d-ecf8-4e05-905f-a2e63f9dc28f",
   "metadata": {},
   "source": [
    "## Test 34 Cochran’s test for variance outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34db7f67-5498-4061-8ef1-7bc90bce89ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No outliers detected.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def cochran_test(data, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Perform Cochran's test for outliers based on variance.\n",
    "\n",
    "    Parameters:\n",
    "    data (array-like): Array of data values.\n",
    "    alpha (float): Significance level (default is 0.05).\n",
    "\n",
    "    Returns:\n",
    "    bool: True if outliers are detected, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(data)\n",
    "    k = 3  # Number of groups (minimum 3 to perform Cochran's test)\n",
    "\n",
    "    # Split the data into k groups\n",
    "    groups = np.array_split(data, k)\n",
    "\n",
    "    # Compute variances for each group\n",
    "    variances = [np.var(group, ddof=1) for group in groups]\n",
    "\n",
    "    # Compute Cochran's test statistic\n",
    "    Q = max(variances) / sum(variances)\n",
    "\n",
    "    # Compute critical value from Chi-square distribution\n",
    "    critical_value = chi2.ppf(1 - alpha, k - 1)\n",
    "\n",
    "    # Perform Cochran's test\n",
    "    if Q > critical_value:\n",
    "        return True  # Outliers detected\n",
    "    else:\n",
    "        return False  # No outliers detected\n",
    "\n",
    "# Example usage:\n",
    "data = [2, 4, 6, 8, 10, 100]  # Sample data\n",
    "outliers_detected = cochran_test(data)\n",
    "if outliers_detected:\n",
    "    print(\"Outliers detected.\")\n",
    "else:\n",
    "    print(\"No outliers detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488029b3-b28e-48b4-b5cc-aef98dbc18c1",
   "metadata": {},
   "source": [
    "## Test 35 The Kolmogorov–Smirnov test for goodness of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff878d5d-5344-4284-bf29-407ac03521aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS Statistic: 0.03737519429804048\n",
      "P-value: 0.11930823166569182\n",
      "Fail to reject null hypothesis: Sample distribution is not significantly different from theoretical distribution.\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Generate a sample data\n",
    "np.random.seed(0)\n",
    "sample_data = np.random.normal(loc=0, scale=1, size=1000)\n",
    "\n",
    "# Define the theoretical distribution to test against (e.g., normal distribution)\n",
    "theoretical_distribution = stats.norm\n",
    "\n",
    "# Perform the Kolmogorov-Smirnov test\n",
    "ks_statistic, p_value = stats.kstest(sample_data, theoretical_distribution.cdf)\n",
    "\n",
    "# Print the results\n",
    "print(\"KS Statistic:\", ks_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject null hypothesis: Sample distribution is significantly different from theoretical distribution.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis: Sample distribution is not significantly different from theoretical distribution.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9884757a-e074-4c81-9205-97671b9d22dc",
   "metadata": {},
   "source": [
    "## Test 36 The Kolmogorov–Smirnov test for comparing two populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8477711-c7f9-48f5-a79f-5340f4c11100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS Statistic: 0.248\n",
      "P-value: 2.104700973377179e-27\n",
      "Reject the null hypothesis: The two samples do not come from the same distribution.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Generate two sample datasets\n",
    "np.random.seed(0)\n",
    "sample1 = np.random.normal(loc=0, scale=1, size=1000)\n",
    "sample2 = np.random.normal(loc=0.5, scale=1, size=1000)\n",
    "\n",
    "# Perform Kolmogorov-Smirnov test\n",
    "statistic, p_value = ks_2samp(sample1, sample2)\n",
    "\n",
    "# Print results\n",
    "print(\"KS Statistic:\", statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The two samples do not come from the same distribution.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference between the two samples.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad9e7c9-dec2-47c0-ba1e-5a7a934bde66",
   "metadata": {},
   "source": [
    "## Test 37 The χ2-test for goodness of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37cba74c-b2c1-4285-99d9-476dc62670b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square statistic: 5.0\n",
      "Critical value: 5.991464547107979\n",
      "Fail to reject null hypothesis: There is no significant difference between observed and expected frequencies.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# Observed frequencies\n",
    "observed = np.array([50, 30, 20])\n",
    "\n",
    "# Expected frequencies\n",
    "expected = np.array([40, 40, 20])\n",
    "\n",
    "# Degree of freedom\n",
    "df = len(observed) - 1\n",
    "\n",
    "# Compute chi-square statistic\n",
    "chi_sq_stat = np.sum((observed - expected) ** 2 / expected)\n",
    "\n",
    "# Compute critical value for chi-square distribution\n",
    "alpha = 0.05  # Significance level\n",
    "critical_value = chi2.ppf(1 - alpha, df)\n",
    "\n",
    "# Compare chi-square statistic with critical value\n",
    "print(\"Chi-square statistic:\", chi_sq_stat)\n",
    "print(\"Critical value:\", critical_value)\n",
    "\n",
    "if chi_sq_stat > critical_value:\n",
    "    print(\"Reject null hypothesis: There is a significant difference between observed and expected frequencies.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis: There is no significant difference between observed and expected frequencies.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77899c10-576a-455a-8cab-0090f872f9cd",
   "metadata": {},
   "source": [
    "## Test 38 The χ2-test for compatibility of K counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e218798-3032-47ee-9315-6e98c11253a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square Statistic: 5.833333333333334\n",
      "P-value: 0.05411376622282158\n",
      "Degrees of Freedom: 2\n",
      "Expected counts:\n",
      " [[15. 15. 15.]\n",
      " [20. 20. 20.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Create example counts data\n",
    "observed_counts = np.array([[10, 15, 20],\n",
    "                             [25, 20, 15]])\n",
    "\n",
    "# Perform chi-square test\n",
    "chi2_stat, p_val, dof, expected_counts = chi2_contingency(observed_counts)\n",
    "\n",
    "# Print results\n",
    "print(\"Chi-square Statistic:\", chi2_stat)\n",
    "print(\"P-value:\", p_val)\n",
    "print(\"Degrees of Freedom:\", dof)\n",
    "print(\"Expected counts:\\n\", expected_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f51a81-21e5-449d-86a6-786ecef254df",
   "metadata": {},
   "source": [
    "## Test 39 Fisher’s exact test for consistency in a 2 × 2 table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28dde85-7680-4fdf-8e9d-a47a44c4bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import fisher_exact\n",
    "\n",
    "# Create a 2x2 contingency table\n",
    "table = [[a, b], [c, d]]  # Replace a, b, c, d with your data\n",
    "\n",
    "# Perform Fisher's exact test\n",
    "odds_ratio, p_value = fisher_exact(table)\n",
    "\n",
    "# Output the results\n",
    "print(\"Odds ratio:\", odds_ratio)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c55d36b-5618-4565-84a1-bfd3e5e06d00",
   "metadata": {},
   "source": [
    "## Test 40 The χ2-test for consistency in a 2 × 2 table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7f5edbb-c79d-4a33-be9e-f3ff40051a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square Statistic: 0.011666666666666653\n",
      "P-value: 0.9139858996305869\n",
      "Degrees of Freedom: 1\n",
      "Expected Frequencies:\n",
      "[[10.71428571 19.28571429]\n",
      " [14.28571429 25.71428571]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Define the observed frequencies in a 2x2 table\n",
    "observed = [[10, 20], [15, 25]]\n",
    "\n",
    "# Perform chi-square test for independence\n",
    "chi2_stat, p_val, dof, expected = chi2_contingency(observed)\n",
    "\n",
    "# Print results\n",
    "print(\"Chi-square Statistic:\", chi2_stat)\n",
    "print(\"P-value:\", p_val)\n",
    "print(\"Degrees of Freedom:\", dof)\n",
    "print(\"Expected Frequencies:\")\n",
    "print(expected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6703335-aa7e-4b4f-89ce-d7fef1f89f3d",
   "metadata": {},
   "source": [
    "## Test 41 The χ2-test for consistency in a K × 2 table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b6e9223-758a-4d59-80c9-bee1a6825742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square statistic: 0.8734402852049911\n",
      "p-value: 0.6461522365929351\n",
      "Degrees of freedom: 2\n",
      "Expected frequencies: [[11.78571429 18.21428571]\n",
      " [27.5        42.5       ]\n",
      " [15.71428571 24.28571429]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Create a K x 2 table\n",
    "table = np.array([[10, 20],\n",
    "                  [30, 40],\n",
    "                  [15, 25]])  # Example data\n",
    "\n",
    "# Perform chi-square test\n",
    "chi2, p, dof, expected = chi2_contingency(table)\n",
    "\n",
    "print(\"Chi-square statistic:\", chi2)\n",
    "print(\"p-value:\", p)\n",
    "print(\"Degrees of freedom:\", dof)\n",
    "print(\"Expected frequencies:\", expected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a286ece-731a-4b4a-afc6-1fa588021839",
   "metadata": {},
   "source": [
    "## Test 42 The Cochran test for consistency in an n × K table of dichotomous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34b585e5-1345-4df7-a676-4a8f9de8c2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q Statistic: 0.513888888888889\n",
      "P-value: 0.7734111798597054\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def cochran_q(data):\n",
    "    \"\"\"\n",
    "    Perform Cochran's Q test for consistency in an n × K table of dichotomous data.\n",
    "\n",
    "    Parameters:\n",
    "    data (2D array-like): An n × K table of dichotomous data.\n",
    "\n",
    "    Returns:\n",
    "    q_statistic (float): Cochran's Q test statistic.\n",
    "    p_value (float): Corresponding p-value.\n",
    "    \"\"\"\n",
    "\n",
    "    data = np.array(data)\n",
    "    n, k = data.shape\n",
    "\n",
    "    # Calculate row totals and overall totals\n",
    "    row_totals = np.sum(data, axis=1)\n",
    "    overall_total = np.sum(data)\n",
    "\n",
    "    # Calculate Q statistic\n",
    "    q_statistic = ((k - 1) * (n - 1) * (np.sum((row_totals - (overall_total / k))**2))) / (overall_total * (k * (n - 1) - np.sum(row_totals**2 / overall_total)))\n",
    "\n",
    "    # Calculate degrees of freedom\n",
    "    df = k - 1\n",
    "\n",
    "    # Calculate p-value\n",
    "    p_value = 1 - chi2.cdf(q_statistic, df)\n",
    "\n",
    "    return q_statistic, p_value\n",
    "\n",
    "# Example usage:\n",
    "data = [[1, 0, 1],\n",
    "        [0, 1, 0],\n",
    "        [1, 1, 1],\n",
    "        [0, 0, 1]]\n",
    "\n",
    "q_statistic, p_value = cochran_q(data)\n",
    "print(\"Q Statistic:\", q_statistic)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b243c34b-0b8b-45b9-8679-5191ccb2bd55",
   "metadata": {},
   "source": [
    "## Test 43 The χ2-test for consistency in a 2 × K table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9ef5c6f-535b-4c6c-88a6-37c03af6f45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square Statistic: 0.27692307692307694\n",
      "P-value: 0.870696738961232\n",
      "Degrees of Freedom: 2\n",
      "Expected Frequencies:\n",
      "[[11.11111111 20.         28.88888889]\n",
      " [13.88888889 25.         36.11111111]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def chi_square_test(table):\n",
    "    \"\"\"\n",
    "    Perform chi-square test for consistency in a 2 × K table.\n",
    "    \n",
    "    Parameters:\n",
    "    table : array_like\n",
    "        A 2D array representing the contingency table. Rows correspond to the two groups,\n",
    "        and columns correspond to the categories.\n",
    "\n",
    "    Returns:\n",
    "    chi2_stat : float\n",
    "        The test statistic.\n",
    "    p_value : float\n",
    "        The p-value of the test.\n",
    "    degrees_of_freedom : int\n",
    "        Degrees of freedom.\n",
    "    expected : ndarray\n",
    "        The expected frequencies, based on the marginal sums of the table.\n",
    "    \"\"\"\n",
    "    chi2_stat, p_value, dof, expected = chi2_contingency(table)\n",
    "    return chi2_stat, p_value, dof, expected\n",
    "\n",
    "# Example usage:\n",
    "table = np.array([[10, 20, 30], [15, 25, 35]])\n",
    "chi2_stat, p_value, dof, expected = chi_square_test(table)\n",
    "print(\"Chi-square Statistic:\", chi2_stat)\n",
    "print(\"P-value:\", p_value)\n",
    "print(\"Degrees of Freedom:\", dof)\n",
    "print(\"Expected Frequencies:\")\n",
    "print(expected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa1c915-1be6-4836-8a9c-6809673744fe",
   "metadata": {},
   "source": [
    "## Test 44 The χ2-test for independence in a p × q table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1ae1a11-eee1-4c2a-9341-16bf75989b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square statistic: 0.27692307692307694\n",
      "p-value: 0.870696738961232\n",
      "Degrees of freedom: 2\n",
      "Expected frequencies table:\n",
      "[[11.11111111 20.         28.88888889]\n",
      " [13.88888889 25.         36.11111111]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Define your p x q table as a numpy array\n",
    "observed_table = np.array([[10, 20, 30],\n",
    "                           [15, 25, 35]])\n",
    "\n",
    "# Perform chi-square test for independence\n",
    "chi2, p, dof, expected = chi2_contingency(observed_table)\n",
    "\n",
    "# Print the results\n",
    "print(\"Chi-square statistic:\", chi2)\n",
    "print(\"p-value:\", p)\n",
    "print(\"Degrees of freedom:\", dof)\n",
    "print(\"Expected frequencies table:\")\n",
    "print(expected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a838387-c585-4238-a535-b96895e7cdce",
   "metadata": {},
   "source": [
    "## Test 45 The sign test for a median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6cdbb24a-22b4-4d35-850a-7a592edbced2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of successes: 5\n",
      "p-value: 1276\n"
     ]
    }
   ],
   "source": [
    "def sign_test(sample, median_hypothesis):\n",
    "    \"\"\"\n",
    "    Performs the sign test for a median.\n",
    "    \n",
    "    Parameters:\n",
    "        sample (list): A list of numeric values representing the sample.\n",
    "        median_hypothesis (float): The hypothesized median value.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A tuple containing the number of successes and the p-value.\n",
    "    \"\"\"\n",
    "    # Counting the number of successes\n",
    "    successes = sum(1 for value in sample if value > median_hypothesis)\n",
    "    \n",
    "    # Assuming two-tailed test, so successes greater than median_hypothesis\n",
    "    # and successes less than median_hypothesis are equally important\n",
    "    n = len(sample)\n",
    "    k = successes\n",
    "    p_value = 0\n",
    "    \n",
    "    # Calculate the p-value using the binomial distribution\n",
    "    for i in range(k, n+1):\n",
    "        p_value += binomial_coefficient(n, i)\n",
    "    \n",
    "    # Assuming two-tailed test, multiply by 2\n",
    "    p_value *= 2\n",
    "    \n",
    "    return successes, p_value\n",
    "\n",
    "def binomial_coefficient(n, k):\n",
    "    \"\"\"\n",
    "    Calculates the binomial coefficient (n choose k).\n",
    "    \n",
    "    Parameters:\n",
    "        n (int): Total number of trials.\n",
    "        k (int): Number of successes.\n",
    "        \n",
    "    Returns:\n",
    "        int: Binomial coefficient value.\n",
    "    \"\"\"\n",
    "    if k < 0 or k > n:\n",
    "        return 0\n",
    "    if k == 0 or k == n:\n",
    "        return 1\n",
    "    \n",
    "    numerator = 1\n",
    "    denominator = 1\n",
    "    for i in range(min(k, n - k)):\n",
    "        numerator *= n - i\n",
    "        denominator *= i + 1\n",
    "    \n",
    "    return numerator // denominator\n",
    "\n",
    "# Example usage:\n",
    "sample = [8, 5, 6, 7, 5, 7, 9, 5, 8, 6]\n",
    "median_hypothesis = 6.5\n",
    "successes, p_value = sign_test(sample, median_hypothesis)\n",
    "print(\"Number of successes:\", successes)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53b8c7ba-5b49-48ab-bb67-234d35336fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median is consistent with the hypothesized value.\n"
     ]
    }
   ],
   "source": [
    "def sign_test(data, median):\n",
    "    above_count = 0\n",
    "    below_count = 0\n",
    "\n",
    "    for value in data:\n",
    "        if value > median:\n",
    "            above_count += 1\n",
    "        elif value < median:\n",
    "            below_count += 1\n",
    "\n",
    "    if above_count == below_count:\n",
    "        print(\"The median is consistent with the hypothesized value.\")\n",
    "    else:\n",
    "        print(\"The median is not consistent with the hypothesized value.\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "data = [25, 30, 35, 40, 45, 50, 55]\n",
    "median = 40\n",
    "sign_test(data, median)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4296c9c8-221b-4b1b-8c4c-8243418d034e",
   "metadata": {},
   "source": [
    "## Test 46 The sign test for two medians (paired observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e37ac8b-d972-4984-ac67-7a1f5d3e70c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 1\n",
      "P-value: 0.375\n"
     ]
    }
   ],
   "source": [
    "def sign_test(data1, data2):\n",
    "    if len(data1) != len(data2):\n",
    "        raise ValueError(\"The two datasets must have the same length\")\n",
    "\n",
    "    n = len(data1)\n",
    "    signs = [1 if data1[i] > data2[i] else -1 if data1[i] < data2[i] else 0 for i in range(n)]\n",
    "    positive_count = sum(1 for sign in signs if sign == 1)\n",
    "    negative_count = sum(1 for sign in signs if sign == -1)\n",
    "    \n",
    "    # Calculate the test statistic\n",
    "    T = min(positive_count, negative_count)\n",
    "    \n",
    "    # Calculate the p-value using binomial distribution\n",
    "    from scipy.stats import binom\n",
    "    p_value = 2 * min(binom.cdf(T, n, 0.5), 1 - binom.cdf(T - 1, n, 0.5))\n",
    "    \n",
    "    return T, p_value\n",
    "\n",
    "# Example usage:\n",
    "data1 = [12, 15, 18, 20, 21]\n",
    "data2 = [11, 14, 16, 19, 22]\n",
    "\n",
    "T, p_value = sign_test(data1, data2)\n",
    "print(\"Test Statistic:\", T)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc802c8-226b-4e81-b37e-5ffa54400fd3",
   "metadata": {},
   "source": [
    "## Test 47 The signed rank test for a mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd626f17-cac7-42d9-b95c-cd0c466492bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic: 12\n",
      "p-value: 0.5408179042426178\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def signed_rank_test(data, mu0):\n",
    "    \"\"\"\n",
    "    Perform the signed rank test for a mean.\n",
    "\n",
    "    Parameters:\n",
    "        data (array-like): The sample data.\n",
    "        mu0 (float): The hypothesized mean.\n",
    "\n",
    "    Returns:\n",
    "        (float): The test statistic.\n",
    "        (float): The p-value.\n",
    "    \"\"\"\n",
    "    # Calculate differences from the hypothesized mean\n",
    "    differences = np.array(data) - mu0\n",
    "\n",
    "    # Get the absolute differences and ranks\n",
    "    abs_diff = np.abs(differences)\n",
    "    ranks = np.argsort(abs_diff) + 1\n",
    "\n",
    "    # Calculate the test statistic as the sum of signed ranks\n",
    "    test_statistic = np.sum(np.sign(differences) * ranks)\n",
    "\n",
    "    # Calculate the p-value using the normal approximation\n",
    "    n = len(data)\n",
    "    expected_mean = 0\n",
    "    expected_variance = (n * (n + 1) * (2 * n + 1)) / 6\n",
    "    expected_standard_deviation = np.sqrt(expected_variance)\n",
    "    z = test_statistic / expected_standard_deviation\n",
    "    p_value = 2 * norm.cdf(-np.abs(z))\n",
    "\n",
    "    return test_statistic, p_value\n",
    "\n",
    "# Example usage:\n",
    "data = [13, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
    "mu0 = 18  # Hypothesized mean\n",
    "\n",
    "test_statistic, p_value = signed_rank_test(data, mu0)\n",
    "print(\"Test statistic:\", test_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1e5b7bd-877f-4802-82fd-12339c21eec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic (manual): 13\n",
      "P-value (manual): 0.001953125\n",
      "Test statistic (Wilcoxon): 0.0\n",
      "P-value (Wilcoxon): 0.001953125\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# Sample data\n",
    "data = [21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n",
    "\n",
    "# Hypothesized mean\n",
    "mu = 25\n",
    "\n",
    "# Calculate the differences from the hypothesized mean\n",
    "differences = [x - mu for x in data]\n",
    "\n",
    "# Compute the absolute differences and ranks\n",
    "absolute_differences = [abs(diff) for diff in differences]\n",
    "sorted_indices = sorted(range(len(absolute_differences)), key=lambda k: absolute_differences[k])\n",
    "ranks = [0] * len(sorted_indices)\n",
    "for i, idx in enumerate(sorted_indices):\n",
    "    ranks[idx] = i + 1\n",
    "\n",
    "# Calculate the test statistic\n",
    "T = sum([rank * (1 if diff > 0 else -1) for rank, diff in zip(ranks, differences)])\n",
    "\n",
    "# Perform the signed rank test using Wilcoxon signed-rank test\n",
    "statistic, p_value = wilcoxon(data, alternative='two-sided')\n",
    "\n",
    "# Output results\n",
    "print(\"Test statistic (manual):\", T)\n",
    "print(\"P-value (manual):\", p_value)\n",
    "print(\"Test statistic (Wilcoxon):\", statistic)\n",
    "print(\"P-value (Wilcoxon):\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b59980-67d2-4d03-bae8-c074e53d6ed3",
   "metadata": {},
   "source": [
    "## Test 48 The signed rank test for two means (paired observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94099299-e05d-4e3e-b8ee-26045cb9033d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic (W): 23\n",
      "p-value: 0.001953125\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# Example data\n",
    "before = [22, 20, 25, 28, 18, 24, 21, 19, 23, 27]\n",
    "after = [25, 24, 26, 29, 22, 27, 24, 20, 26, 28]\n",
    "\n",
    "# Compute differences\n",
    "differences = [after[i] - before[i] for i in range(len(before))]\n",
    "\n",
    "# Compute signed ranks\n",
    "signed_ranks = [(abs(diff), -1) if diff < 0 else (abs(diff), 1) for diff in differences]\n",
    "signed_ranks.sort()\n",
    "\n",
    "# Assign ranks\n",
    "rank = 1\n",
    "for i in range(len(signed_ranks)):\n",
    "    if i > 0 and signed_ranks[i][0] == signed_ranks[i-1][0]:\n",
    "        signed_ranks[i] = (signed_ranks[i][0], signed_ranks[i-1][1])\n",
    "    else:\n",
    "        signed_ranks[i] = (rank, signed_ranks[i][1])\n",
    "        rank += 1\n",
    "\n",
    "# Calculate the test statistic\n",
    "W = sum(rank * sign for rank, sign in signed_ranks)\n",
    "\n",
    "# Calculate the p-value using Wilcoxon signed-rank test\n",
    "_, p_value = wilcoxon(before, after, zero_method='wilcox')\n",
    "\n",
    "print(\"Test Statistic (W):\", W)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef736f0-c85b-4f3b-bb8e-c15a4d825494",
   "metadata": {},
   "source": [
    "## Test 49 The Wilcoxon inversion test (U-test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8045e255-936a-48e4-8f60-17c7764862ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U Statistic: 74\n",
      "Z Statistic: 1.8142294704442907\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def wilcoxon_inversion_test(data1, data2):\n",
    "    n1, n2 = len(data1), len(data2)\n",
    "    ranks = sorted([(x, 0) for x in data1] + [(x, 1) for x in data2])\n",
    "    ranks_diff = sum(r[1] for r in ranks)\n",
    "    \n",
    "    u_stat = sum((i + 1) * r[1] for i, r in enumerate(ranks))\n",
    "    u_stat -= n1 * (n1 + 1) // 2\n",
    "    \n",
    "    mean_u = n1 * n2 / 2\n",
    "    var_u = n1 * n2 * (n1 + n2 + 1) / 12\n",
    "    \n",
    "    z_stat = (u_stat - mean_u) / (var_u ** 0.5)\n",
    "    \n",
    "    return u_stat, z_stat\n",
    "\n",
    "# Example usage:\n",
    "data1 = [22, 14, 15, 18, 20, 21, 15, 17, 18, 24]\n",
    "data2 = [19, 16, 17, 21, 23, 21, 20, 22, 24, 25]\n",
    "u_stat, z_stat = wilcoxon_inversion_test(data1, data2)\n",
    "print(\"U Statistic:\", u_stat)\n",
    "print(\"Z Statistic:\", z_stat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6156961c-e612-48d2-9f14-b658e3ac0a0f",
   "metadata": {},
   "source": [
    "## Test 50 The median test of two populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "058f1336-6b2d-4555-9434-8113dd6e6416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Test Results:\n",
      "Median: 0.8080808080808082\n",
      "p-value: 0.36868826936178145\n",
      "Fail to reject null hypothesis: The medians of the two populations are not significantly different.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import median_test\n",
    "\n",
    "# Sample data for two populations\n",
    "pop1 = np.array([17, 21, 20, 25, 22, 18, 15, 16, 19, 24])\n",
    "pop2 = np.array([12, 11, 10, 13, 14, 16, 18, 19, 20, 21])\n",
    "\n",
    "# Calculate median and perform median test\n",
    "median, p_value, _, _ = median_test(pop1, pop2)\n",
    "\n",
    "# Output results\n",
    "print(\"Median Test Results:\")\n",
    "print(\"Median:\", median)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret p-value\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject null hypothesis: The medians of the two populations are significantly different.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis: The medians of the two populations are not significantly different.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd321923-b95f-471a-a1d2-1c652bf06ca6",
   "metadata": {},
   "source": [
    "## Test 51 The median test of K populations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4e0ba21-fe52-4b11-aec3-9a2dc657624b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-squared Statistic: 2.0\n",
      "Degrees of Freedom: 4\n",
      "p-value: 0.7357588823428847\n",
      "Critical Value: 9.487729036781154\n",
      "Fail to reject null hypothesis: There is no significant difference in medians.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def median_test(*populations):\n",
    "    n_groups = len(populations)\n",
    "    \n",
    "    # Combine all observations into a single array\n",
    "    all_observations = np.concatenate(populations)\n",
    "    total_obs = len(all_observations)\n",
    "    \n",
    "    # Calculate overall median\n",
    "    overall_median = np.median(all_observations)\n",
    "    \n",
    "    # Calculate the number of observations above and below the overall median for each group\n",
    "    above_median_counts = []\n",
    "    below_median_counts = []\n",
    "    \n",
    "    for group in populations:\n",
    "        above_median_counts.append(np.sum(group > overall_median))\n",
    "        below_median_counts.append(np.sum(group < overall_median))\n",
    "    \n",
    "    # Create a contingency table\n",
    "    contingency_table = np.array([above_median_counts, below_median_counts])\n",
    "    \n",
    "    # Calculate expected frequencies\n",
    "    row_totals = contingency_table.sum(axis=0)\n",
    "    col_totals = contingency_table.sum(axis=1)\n",
    "    total = contingency_table.sum()\n",
    "    \n",
    "    expected_freq = np.outer(col_totals, row_totals) / total\n",
    "    \n",
    "    # Calculate chi-square statistic\n",
    "    chi_squared_statistic = np.sum((contingency_table - expected_freq)**2 / expected_freq)\n",
    "    \n",
    "    # Degrees of freedom\n",
    "    df = (len(above_median_counts) - 1) * (len(below_median_counts) - 1)\n",
    "    \n",
    "    # Critical value for chi-square test\n",
    "    critical_value = chi2.ppf(0.95, df)\n",
    "    \n",
    "    # Perform hypothesis test\n",
    "    p_value = 1 - chi2.cdf(chi_squared_statistic, df)\n",
    "    \n",
    "    return chi_squared_statistic, df, p_value, critical_value\n",
    "\n",
    "# Example usage:\n",
    "population1 = np.array([1, 2, 3, 4, 5])\n",
    "population2 = np.array([2, 3, 4, 5, 6])\n",
    "population3 = np.array([3, 4, 5, 6, 7])\n",
    "\n",
    "chi_squared, degrees_of_freedom, p_value, critical_value = median_test(population1, population2, population3)\n",
    "print(\"Chi-squared Statistic:\", chi_squared)\n",
    "print(\"Degrees of Freedom:\", degrees_of_freedom)\n",
    "print(\"p-value:\", p_value)\n",
    "print(\"Critical Value:\", critical_value)\n",
    "\n",
    "if chi_squared > critical_value:\n",
    "    print(\"Reject null hypothesis: There is a significant difference in medians.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis: There is no significant difference in medians.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5ca5395-62f5-4bec-80fe-6bd882200b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic: 6.666666666666666\n",
      "P-value: 0.0356739933472524\n",
      "Medians: 6.0\n",
      "Contingency table:\n",
      "[[0 2 4]\n",
      " [5 3 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import median_test\n",
    "\n",
    "# Sample data for K populations\n",
    "data = [\n",
    "    [3, 5, 2, 6, 1],\n",
    "    [7, 4, 8, 2, 5],\n",
    "    [9, 12, 6, 10, 8]\n",
    "]\n",
    "\n",
    "# Perform the median test\n",
    "statistic, p_value, medians, conting_tab = median_test(*data)\n",
    "\n",
    "# Print the results\n",
    "print(\"Test statistic:\", statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "print(\"Medians:\", medians)\n",
    "print(\"Contingency table:\")\n",
    "print(conting_tab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35dd248-1678-4d84-8bf7-6669e5784827",
   "metadata": {},
   "source": [
    "## Test 52 The Wilcoxon–Mann–Whitney rank sum test of two populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45c38a9a-189a-4c72-a756-72fc6fc46794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon–Mann–Whitney test statistic: -0.5222329678670935\n",
      "p-value: 0.6015081344405899\n",
      "The difference in medians is not statistically significant (fail to reject the null hypothesis)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ranksums\n",
    "\n",
    "# Data for two populations\n",
    "population1 = [10, 15, 20, 25, 30]\n",
    "population2 = [12, 18, 22, 27, 32]\n",
    "\n",
    "# Perform the Wilcoxon–Mann–Whitney rank sum test\n",
    "statistic, p_value = ranksums(population1, population2)\n",
    "\n",
    "# Output the results\n",
    "print(\"Wilcoxon–Mann–Whitney test statistic:\", statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "if p_value < 0.05:\n",
    "    print(\"The difference in medians is statistically significant (reject the null hypothesis)\")\n",
    "else:\n",
    "    print(\"The difference in medians is not statistically significant (fail to reject the null hypothesis)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c10c13c-3b02-4a94-88f5-6962f42c1234",
   "metadata": {},
   "source": [
    "## Test 53 The Siegel–Tukey rank sum dispersion test of two variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63b0757e-4be1-4597-8fdf-c2d014ee3206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic: -191.07301097326138\n",
      "P-value: 0.6787862389035584\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ranksums\n",
    "\n",
    "def siegel_tukey_rank_sum_dispersion_test(data1, data2):\n",
    "    \"\"\"\n",
    "    Perform Siegel-Tukey rank sum dispersion test for comparing variances of two samples.\n",
    "    \n",
    "    Parameters:\n",
    "        data1 (array-like): First sample data.\n",
    "        data2 (array-like): Second sample data.\n",
    "        \n",
    "    Returns:\n",
    "        statistic (float): The test statistic.\n",
    "        p_value (float): The p-value of the test.\n",
    "    \"\"\"\n",
    "    # Concatenate the data\n",
    "    all_data = np.concatenate([data1, data2])\n",
    "    \n",
    "    # Rank the concatenated data\n",
    "    ranked_data = np.argsort(np.argsort(all_data))\n",
    "    \n",
    "    # Calculate the rank sum for each group\n",
    "    rank_sum_1 = np.sum(ranked_data[:len(data1)])\n",
    "    rank_sum_2 = np.sum(ranked_data[len(data1):])\n",
    "    \n",
    "    # Calculate the test statistic\n",
    "    n1 = len(data1)\n",
    "    n2 = len(data2)\n",
    "    statistic = (n1 * rank_sum_2 - n2 * rank_sum_1) / np.sqrt(n1 * n2 * (n1 + n2 + 1) / 12)\n",
    "    \n",
    "    # Calculate the p-value\n",
    "    p_value = 2 * min(ranksums(data1, data2).pvalue, 1 - ranksums(data1, data2).pvalue)\n",
    "    \n",
    "    return statistic, p_value\n",
    "\n",
    "# Example usage:\n",
    "data1 = np.random.normal(loc=0, scale=1, size=100)\n",
    "data2 = np.random.normal(loc=0, scale=2, size=100)\n",
    "\n",
    "statistic, p_value = siegel_tukey_rank_sum_dispersion_test(data1, data2)\n",
    "print(\"Test statistic:\", statistic)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95ba5e1-67b1-4393-abf9-b8d87ea2e57f",
   "metadata": {},
   "source": [
    "## Test 54 The Kruskall–Wallis rank sum test of K populations (H-test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e006ca9a-5bbb-46ff-8eaf-df9888434369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal-Wallis H-test:\n",
      "H-statistic: 0.987050359712227\n",
      "p-value: 0.6104705780126923\n",
      "Fail to reject null hypothesis: There are no significant differences between the groups.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "# Data for K groups\n",
    "group1 = [10, 20, 30, 40, 50]\n",
    "group2 = [15, 25, 35, 45, 55]\n",
    "group3 = [5, 15, 25, 35, 45]\n",
    "\n",
    "# Perform Kruskal-Wallis test\n",
    "H, p_value = kruskal(group1, group2, group3)\n",
    "\n",
    "# Print the results\n",
    "print(\"Kruskal-Wallis H-test:\")\n",
    "print(\"H-statistic:\", H)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject null hypothesis: There are significant differences between the groups.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis: There are no significant differences between the groups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6d9bb2-b56d-45fd-8024-64fb4da3978e",
   "metadata": {},
   "source": [
    "## Test 55 The rank sum difference test for the multiple comparison of K population means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eecfee36-505a-4617-ae90-134cbfd6ad1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted p-values for multiple comparisons: [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal, ranksums\n",
    "from scipy.stats import rankdata\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "def dunn_posthoc_test(data):\n",
    "    \"\"\"\n",
    "    Perform Dunn's test for multiple comparisons after Kruskal-Wallis one-way ANOVA\n",
    "    Args:\n",
    "        data: List of arrays containing the different samples\n",
    "    Returns:\n",
    "        p_values: Array of adjusted p-values for multiple comparisons\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    kruskal_result = kruskal(*data)\n",
    "    kruskal_statistic = kruskal_result[0]\n",
    "    kruskal_p = kruskal_result[1]\n",
    "    \n",
    "    if kruskal_p < 0.05:\n",
    "        # Compute ranks\n",
    "        ranks = np.concatenate([rankdata(sample) for sample in data])\n",
    "        \n",
    "        # Compute pairwise comparisons\n",
    "        combinations = [(i, j) for i in range(n) for j in range(i+1, n)]\n",
    "        p_values = []\n",
    "        for i, j in combinations:\n",
    "            data_i, data_j = data[i], data[j]\n",
    "            n_i, n_j = len(data_i), len(data_j)\n",
    "            rank_sum = ranksums(data_i, data_j)[0]\n",
    "            z = rank_sum / np.sqrt((n_i * (n_i + n_j + 1)) / 12)\n",
    "            p_value = 2 * norm.cdf(-np.abs(z))\n",
    "            p_values.append(p_value)\n",
    "        \n",
    "        # Bonferroni correction for multiple comparisons\n",
    "        corrected_p_values = np.array(p_values) * (len(combinations))\n",
    "        corrected_p_values = np.clip(corrected_p_values, 0, 1)  # Clip values to ensure they are within [0, 1]\n",
    "        \n",
    "        return corrected_p_values\n",
    "    else:\n",
    "        print(\"Kruskal-Wallis test not significant, no post-hoc test needed.\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "# Generate some sample data\n",
    "group1 = np.random.normal(loc=0, scale=1, size=20)\n",
    "group2 = np.random.normal(loc=1, scale=1, size=20)\n",
    "group3 = np.random.normal(loc=2, scale=1, size=20)\n",
    "\n",
    "# Perform Dunn's test for multiple comparisons\n",
    "p_values = dunn_posthoc_test([group1, group2, group3])\n",
    "print(\"Adjusted p-values for multiple comparisons:\", p_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e2005b-11ea-4ba4-842c-06107c4b0c44",
   "metadata": {},
   "source": [
    "## Test 56 The rank sum maximum test for the largest K population means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52b8b9f7-8430-4bf6-89ba-c68709219df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 18\n",
      "P-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "def rank_sum_max_test(data, k):\n",
    "    \"\"\"\n",
    "    Perform the rank sum maximum test for the largest K population means.\n",
    "\n",
    "    Parameters:\n",
    "    data (list of arrays): Data for each population.\n",
    "    k (int): Number of populations to consider.\n",
    "\n",
    "    Returns:\n",
    "    test_statistic (float): Test statistic value.\n",
    "    p_value (float): The p-value for the test.\n",
    "    \"\"\"\n",
    "    n = len(data[0])  # Assuming all populations have same sample size\n",
    "    total_ranks = np.concatenate([np.repeat(i+1, len(pop)) for i, pop in enumerate(data)])\n",
    "    test_statistic = np.max(np.array([np.sum(ranks) for ranks in combinations(total_ranks, n*k)]))\n",
    "    # Calculate p-value using Monte Carlo simulation\n",
    "    num_samples = 10000\n",
    "    greater_count = 0\n",
    "    for _ in range(num_samples):\n",
    "        random_ranks = np.random.permutation(total_ranks)\n",
    "        max_test_statistic = np.max(np.array([np.sum(random_ranks[i:i+n*k]) for i in range(len(total_ranks)-(n*k)+1)]))\n",
    "        if max_test_statistic >= test_statistic:\n",
    "            greater_count += 1\n",
    "    p_value = greater_count / num_samples\n",
    "    return test_statistic, p_value\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have data for k populations, each stored in a separate numpy array\n",
    "data = [np.array([1, 2, 3]), np.array([4, 5, 6]), np.array([7, 8, 9])]\n",
    "k = 3\n",
    "test_statistic, p_value = rank_sum_max_test(data, k)\n",
    "print(\"Test Statistic:\", test_statistic)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2547c331-c05f-48f5-b8fc-510769f33eb3",
   "metadata": {},
   "source": [
    "## Test 57 The Steel test for comparing K treatments with a control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d5269d0-60b3-4e79-b6c8-afe2240db8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 1.0\n",
      "P-value: 0.31731050786291415\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import rankdata\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "def steel_test(control, treatments, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Perform the Steel test to compare K treatments with a control.\n",
    "\n",
    "    Parameters:\n",
    "    control (array-like): Data for the control group.\n",
    "    treatments (list of array-like): Data for each treatment group.\n",
    "    alpha (float): Significance level.\n",
    "\n",
    "    Returns:\n",
    "    (statistic, p-value): The test statistic and the p-value.\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(control)\n",
    "    k = len(treatments)\n",
    "\n",
    "    # Compute the differences between each treatment and control\n",
    "    diffs = [np.mean(treatment) - np.mean(control) for treatment in treatments]\n",
    "\n",
    "    # Rank the differences\n",
    "    ranked_diffs = rankdata(diffs)\n",
    "\n",
    "    # Calculate the standard error of the rank sum statistic\n",
    "    std_error = np.sqrt((k * (k + 1) * (2 * k + 1)) / (6 * n))\n",
    "\n",
    "    # Calculate the test statistic\n",
    "    test_statistic = (ranked_diffs[0] - 1) / std_error\n",
    "\n",
    "    # Calculate the p-value using the standard normal distribution\n",
    "    p_value = norm.cdf(-np.abs(test_statistic)) * 2\n",
    "\n",
    "    return test_statistic, p_value\n",
    "\n",
    "# Example usage:\n",
    "control_group = [14, 15, 16, 15, 16]\n",
    "treatment_groups = [[16, 17, 18, 17, 18], [12, 13, 14, 13, 14]]\n",
    "statistic, p_value = steel_test(control_group, treatment_groups)\n",
    "print(\"Test Statistic:\", statistic)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04da48f-ea21-4d47-a7e8-7375aff25c83",
   "metadata": {},
   "source": [
    "## Test 58 The Spearman rank correlation test (paired observations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f5774d-3102-4bbc-8e72-49ff5b11545a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman rank correlation coefficient: 0.9999999999999999\n",
      "p-value: 1.4042654220543672e-24\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Sample data\n",
    "data1 = [14, 15, 16, 17, 18]\n",
    "data2 = [5, 6, 7, 8, 9]\n",
    "\n",
    "# Calculate Spearman rank correlation coefficient and p-value\n",
    "spearman_corr, p_value = stats.spearmanr(data1, data2)\n",
    "\n",
    "print(\"Spearman rank correlation coefficient:\", spearman_corr)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddf7b01-6d98-49de-9630-b54273c551cf",
   "metadata": {},
   "source": [
    "## Test 59 The Kendall rank correlation test (paired observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ae55dce-9e1e-42e2-8e3e-1e89f517313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall's tau: 0.39999999999999997\n",
      "p-value: 0.48333333333333334\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kendalltau\n",
    "\n",
    "# Sample data (replace with your data)\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [2, 3, 1, 5, 4]\n",
    "\n",
    "# Perform Kendall rank correlation test\n",
    "tau, p_value = kendalltau(x, y)\n",
    "\n",
    "print(\"Kendall's tau:\", tau)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c361c8-a3af-4541-a165-2b3bfcb33978",
   "metadata": {},
   "source": [
    "## Test 60 The sequential test for a population mean (variance known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fc8f020-7555-41dc-b06f-f803415aa73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision: Reject, Observations taken: 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sequential_mean_test(data, mu0, sigma, alpha, beta):\n",
    "    \"\"\"\n",
    "    Perform sequential hypothesis test for population mean (variance known).\n",
    "\n",
    "    Parameters:\n",
    "    data (array-like): Data sample\n",
    "    mu0 (float): Null hypothesis population mean\n",
    "    sigma (float): Population standard deviation\n",
    "    alpha (float): Type I error rate (probability of rejecting null hypothesis when it is true)\n",
    "    beta (float): Type II error rate (probability of failing to reject null hypothesis when it is false)\n",
    "\n",
    "    Returns:\n",
    "    str: Decision ('Accept' or 'Reject') and total number of observations taken.\n",
    "    \"\"\"\n",
    "    # Constants for log likelihood ratio\n",
    "    c1 = np.log(beta / (1 - alpha))\n",
    "    c2 = np.log((1 - beta) / alpha)\n",
    "\n",
    "    # Initial values for log likelihood ratio\n",
    "    LR = 0\n",
    "\n",
    "    # Sequential testing\n",
    "    n = 0\n",
    "    for x in data:\n",
    "        n += 1\n",
    "        LR += np.log((1 / (np.sqrt(2 * np.pi) * sigma)) * np.exp(-0.5 * ((x - mu0) / sigma) ** 2))\n",
    "        if LR <= c1:\n",
    "            decision = 'Reject'\n",
    "            break\n",
    "        elif LR >= c2:\n",
    "            decision = 'Accept'\n",
    "            break\n",
    "\n",
    "    return decision, n\n",
    "\n",
    "# Example usage:\n",
    "data_sample = np.random.normal(3.5, 1, 100)  # Generate some sample data\n",
    "mu0 = 3  # Null hypothesis mean\n",
    "sigma = 1  # Known population standard deviation\n",
    "alpha = 0.05  # Type I error rate\n",
    "beta = 0.2  # Type II error rate\n",
    "\n",
    "decision, n = sequential_mean_test(data_sample, mu0, sigma, alpha, beta)\n",
    "print(f\"Decision: {decision}, Observations taken: {n}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37461278-26f7-4d7e-a757-1bb4980d9cd3",
   "metadata": {},
   "source": [
    "## Test 61 The sequential test for a standard deviation (mean known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6452e21-ace6-4877-9e00-6ddd548829e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision: Accept, Number of iterations: 985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marat\\AppData\\Local\\Temp\\ipykernel_13664\\2599959532.py:26: RuntimeWarning: divide by zero encountered in log\n",
      "  k += np.log(np.prod(sigma0 ** 2 / sigma1 ** 2 * np.exp(-0.5 * (data ** 2 / sigma1 ** 2 - data ** 2 / sigma0 ** 2))))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sequential_std_test(data, sigma0, sigma1, alpha, beta, sample_size):\n",
    "    \"\"\"\n",
    "    Perform a sequential test for standard deviation (mean known) using Wald's SPRT.\n",
    "    \n",
    "    Parameters:\n",
    "        data (array-like): The sample data.\n",
    "        sigma0 (float): The null hypothesis standard deviation.\n",
    "        sigma1 (float): The alternative hypothesis standard deviation.\n",
    "        alpha (float): Type I error rate.\n",
    "        beta (float): Type II error rate.\n",
    "        sample_size (int): The sample size for each iteration.\n",
    "    \n",
    "    Returns:\n",
    "        str: Decision ('Reject' or 'Accept') and the number of iterations taken.\n",
    "    \"\"\"\n",
    "    ll_ratio = np.log(sigma1/sigma0)\n",
    "    u = np.log((1 - beta) / alpha)\n",
    "    l = np.log(beta / (1 - alpha))\n",
    "    \n",
    "    s = np.sum(data ** 2)\n",
    "    k = 0\n",
    "    \n",
    "    while l < k < u:\n",
    "        k += np.log(np.prod(sigma0 ** 2 / sigma1 ** 2 * np.exp(-0.5 * (data ** 2 / sigma1 ** 2 - data ** 2 / sigma0 ** 2))))\n",
    "        s += np.sum((np.random.normal(scale=sigma1, size=sample_size)) ** 2)\n",
    "    \n",
    "    if k >= u:\n",
    "        return \"Reject\", int(np.ceil(s / (sigma1 ** 2)))\n",
    "    else:\n",
    "        return \"Accept\", int(np.ceil(s / (sigma0 ** 2)))\n",
    "\n",
    "# Example usage:\n",
    "np.random.seed(42)  # for reproducibility\n",
    "data = np.random.normal(loc=0, scale=1, size=1000)  # Sample data\n",
    "sigma0 = 1  # Null hypothesis standard deviation\n",
    "sigma1 = 2  # Alternative hypothesis standard deviation\n",
    "alpha = 0.05  # Type I error rate\n",
    "beta = 0.10  # Type II error rate\n",
    "sample_size = 10  # Sample size for each iteration\n",
    "\n",
    "decision, iterations = sequential_std_test(data, sigma0, sigma1, alpha, beta, sample_size)\n",
    "print(f\"Decision: {decision}, Number of iterations: {iterations}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc3f151-3c56-4615-9b5f-ca0ef6f08465",
   "metadata": {},
   "source": [
    "## Test 62 The sequential test for a dichotomous classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84bdcf69-4553-4692-8275-366daf7815bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample is classified as category: 0\n"
     ]
    }
   ],
   "source": [
    "def sequential_test(sample_stream, stopping_criteria):\n",
    "    \"\"\"\n",
    "    Sequential test for dichotomous classification.\n",
    "\n",
    "    Args:\n",
    "    sample_stream: A generator or iterable that yields samples.\n",
    "    stopping_criteria: A function that takes the current sample and returns True if the\n",
    "                       sequential test should stop, False otherwise.\n",
    "\n",
    "    Returns:\n",
    "    '0' if the sample is classified into category 0, '1' if it's classified into category 1.\n",
    "    \"\"\"\n",
    "    for sample in sample_stream:\n",
    "        if stopping_criteria(sample):\n",
    "            return '1'  # Classify as category 1\n",
    "        else:\n",
    "            return '0'  # Classify as category 0\n",
    "\n",
    "# Example usage:\n",
    "# Let's say we have a stream of samples represented as a list.\n",
    "samples = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "# Define stopping criteria (e.g., if the sample is greater than 0.5)\n",
    "def stopping_criteria(sample):\n",
    "    return sample > 0.5\n",
    "\n",
    "# Perform sequential test\n",
    "result = sequential_test(samples, stopping_criteria)\n",
    "print(\"The sample is classified as category:\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a15571-56a5-4f7b-a5e6-5281696ba5ea",
   "metadata": {},
   "source": [
    "## Test 63 The adjacency test for randomness of fluctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3ce323f-541d-4bc3-b050-3777e66ace29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passes adjacency test: True\n"
     ]
    }
   ],
   "source": [
    "def adjacency_test(sequence):\n",
    "    \"\"\"\n",
    "    Perform the adjacency test for randomness of fluctuations on a sequence.\n",
    "    \n",
    "    Args:\n",
    "    - sequence: A list or array of numerical values.\n",
    "    \n",
    "    Returns:\n",
    "    - True if the sequence passes the adjacency test, False otherwise.\n",
    "    \"\"\"\n",
    "    n = len(sequence)\n",
    "    adj_count = 0  # Count of adjacent pairs with fluctuations of the same sign\n",
    "    \n",
    "    for i in range(n - 1):\n",
    "        if (sequence[i] - sequence[i+1]) * (sequence[i] - sequence[i-1]) > 0:\n",
    "            adj_count += 1\n",
    "    \n",
    "    # Calculate the expected number of adjacent pairs\n",
    "    expected_adj_count = (n - 1) / 3\n",
    "    \n",
    "    # Perform chi-square test\n",
    "    chi_square = ((adj_count - expected_adj_count) ** 2) / expected_adj_count\n",
    "    \n",
    "    # Set a threshold for significance level (e.g., 0.05)\n",
    "    threshold = 0.05\n",
    "    \n",
    "    # Compare chi-square value with critical value for significance\n",
    "    if chi_square < threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Example usage:\n",
    "sequence = [1, 2, 3, 2, 4, 5, 6, 7, 8]\n",
    "result = adjacency_test(sequence)\n",
    "print(\"Passes adjacency test:\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd546da-fab2-466e-b10c-07c42bce57c9",
   "metadata": {},
   "source": [
    "## Test 64 The serial correlation test for randomness of fluctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16ff404c-d034-44b2-be9d-291f962ee3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      lb_stat  lb_pvalue\n",
      "10  13.169306   0.214359\n",
      "Autocorrelation: [ 1.          0.07149068  0.13664497  0.03486707 -0.0330982   0.02947577\n",
      "  0.07295543  0.19055283  0.18172587 -0.10907537  0.08437772 -0.04972481\n",
      "  0.1803898   0.21076136  0.08460036  0.2018417  -0.10940056 -0.07306135\n",
      " -0.02333271 -0.02405557  0.03927974]\n",
      "Ljung-Box test p-value: 0.48333333333333334\n",
      "Fail to reject null hypothesis: No evidence of serial correlation.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Generate some random data\n",
    "np.random.seed(0)\n",
    "data = np.random.normal(size=100)\n",
    "\n",
    "# Compute autocorrelation\n",
    "acf = sm.tsa.acf(data)\n",
    "\n",
    "# Compute the Ljung-Box test for serial correlation\n",
    "# Change the lags parameter according to your data size and expected autocorrelation\n",
    "test_result = sm.stats.acorr_ljungbox(data, lags=[10])\n",
    "print(test_result)\n",
    "# Extract the p-value from the test result\n",
    "#p_value = test_result[1][0]\n",
    "\n",
    "# Print the results\n",
    "print(\"Autocorrelation:\", acf)\n",
    "print(\"Ljung-Box test p-value:\", p_value)\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject null hypothesis: Serial correlation is present.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis: No evidence of serial correlation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343cbd82-3b66-4313-b243-d33192d93699",
   "metadata": {},
   "source": [
    "## Test 65 The turning point test for randomness of fluctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e74d7f9-aef6-4108-a9bc-8e1d9c8b43aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of up-turns: 1\n",
      "Number of down-turns: 0\n",
      "Expected number of turns: 7.0\n",
      "Test statistic (z-score): -4.69476477861571\n",
      "Reject null hypothesis: Data is not consistent with randomness.\n"
     ]
    }
   ],
   "source": [
    "def turning_point_test(data):\n",
    "    \"\"\"Perform the turning point test for randomness.\"\"\"\n",
    "    # Initialize counters for turning points\n",
    "    up_turns = 0\n",
    "    down_turns = 0\n",
    "    \n",
    "    # Iterate through the data to count turning points\n",
    "    for i in range(1, len(data)-1):\n",
    "        if data[i-1] < data[i] > data[i+1]:\n",
    "            up_turns += 1\n",
    "        elif data[i-1] > data[i] < data[i+1]:\n",
    "            down_turns += 1\n",
    "    \n",
    "    # Calculate the test statistic\n",
    "    n = len(data)\n",
    "    expected_turns = (2 * n - 1) / 3\n",
    "    variance = (16 * n - 29) / 90\n",
    "    z = (up_turns - expected_turns) / (variance ** 0.5)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Number of up-turns:\", up_turns)\n",
    "    print(\"Number of down-turns:\", down_turns)\n",
    "    print(\"Expected number of turns:\", expected_turns)\n",
    "    print(\"Test statistic (z-score):\", z)\n",
    "    \n",
    "    # Perform hypothesis test\n",
    "    significance_level = 0.05\n",
    "    if abs(z) > 1.96:  # For a significance level of 0.05 (two-tailed test)\n",
    "        print(\"Reject null hypothesis: Data is not consistent with randomness.\")\n",
    "    else:\n",
    "        print(\"Fail to reject null hypothesis: Data is consistent with randomness.\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "data = [4, 5, 6, 7, 8, 9, 8, 7, 6, 5, 4]  # Sample data\n",
    "turning_point_test(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc350d2-f917-4869-a767-0cb5c8218d5f",
   "metadata": {},
   "source": [
    "## Test 66 The difference sign test for randomness in a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2b15a62-05f4-4114-a3dc-b182c0abd35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no significant difference between the samples.\n"
     ]
    }
   ],
   "source": [
    "def difference_sign_test(sample1, sample2):\n",
    "    \"\"\"\n",
    "    Performs the difference sign test for randomness in two related samples.\n",
    "\n",
    "    Parameters:\n",
    "    sample1 (list): The first sample.\n",
    "    sample2 (list): The second sample.\n",
    "\n",
    "    Returns:\n",
    "    str: A message indicating whether there is a significant difference or not.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(sample1) != len(sample2):\n",
    "        raise ValueError(\"Samples must be of the same length.\")\n",
    "\n",
    "    n = len(sample1)\n",
    "    count_positive = 0\n",
    "    count_negative = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        diff = sample1[i] - sample2[i]\n",
    "        if diff > 0:\n",
    "            count_positive += 1\n",
    "        elif diff < 0:\n",
    "            count_negative += 1\n",
    "\n",
    "    # Calculate the test statistic\n",
    "    D = min(count_positive, count_negative)\n",
    "\n",
    "    # Calculate critical value assuming alpha = 0.05 (for two-tailed test)\n",
    "    critical_value = round(0.95 ** n * n)\n",
    "\n",
    "    if D <= critical_value:\n",
    "        return \"There is no significant difference between the samples.\"\n",
    "    else:\n",
    "        return \"There is a significant difference between the samples.\"\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "sample1 = [3, 4, 5, 6, 7]\n",
    "sample2 = [4, 3, 6, 5, 8]\n",
    "result = difference_sign_test(sample1, sample2)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d2a19-bee4-40ff-b789-e1040accbfb5",
   "metadata": {},
   "source": [
    "## Test 67 The run test on successive differences for randomness in a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35df9332-e3c2-4d07-b058-02a165cfadff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z Statistic: 0.5525789639955379\n",
      "Fail to reject the null hypothesis: The sequence is random.\n"
     ]
    }
   ],
   "source": [
    "def run_test(data):\n",
    "    runs = 1\n",
    "    n = len(data)\n",
    "\n",
    "    # Determine the number of runs\n",
    "    for i in range(1, n):\n",
    "        if data[i] != data[i - 1]:\n",
    "            runs += 1\n",
    "\n",
    "    # Calculate expected number of runs and variance\n",
    "    expected_runs = (2 * n - 1) / 3\n",
    "    variance = (16 * n - 29) / 90\n",
    "\n",
    "    # Calculate Z statistic\n",
    "    z = (runs - expected_runs) / variance**0.5\n",
    "\n",
    "    return z\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Example dataset\n",
    "    data = [1, 0, 1, 1, 0, 1, 0, 0, 1, 1]\n",
    "    \n",
    "    # Calculate Z statistic\n",
    "    z_statistic = run_test(data)\n",
    "    print(\"Z Statistic:\", z_statistic)\n",
    "\n",
    "    # Interpretation\n",
    "    if abs(z_statistic) >= 1.96:  # For 5% significance level\n",
    "        print(\"Reject the null hypothesis: The sequence is not random.\")\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis: The sequence is random.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d456f6e-a4cb-40bd-911b-58def9075f09",
   "metadata": {},
   "source": [
    "## Test 68 The run test for randomness of two related samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e458f51-2928-4e3e-98cc-8492e44a57da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 8\n",
      "P-value: 0.17971249487899976\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "def run_test(x1, x2, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Perform the run test for randomness of two related samples.\n",
    "    \n",
    "    Parameters:\n",
    "    x1 : array-like\n",
    "        First sample.\n",
    "    x2 : array-like\n",
    "        Second sample.\n",
    "    alpha : float, optional\n",
    "        Significance level. Default is 0.05.\n",
    "    \n",
    "    Returns:\n",
    "    test_statistic : float\n",
    "        Test statistic value.\n",
    "    p_value : float\n",
    "        p-value of the test.\n",
    "    \"\"\"\n",
    "    n1 = len(x1)\n",
    "    n2 = len(x2)\n",
    "    n = n1 + n2\n",
    "    \n",
    "    runs = 1\n",
    "    for i in range(1, n):\n",
    "        if (x1[i % n1] > x1[(i-1) % n1]) != (x2[i % n2] > x2[(i-1) % n2]):\n",
    "            runs += 1\n",
    "    \n",
    "    mean_runs = ((2 * n1 * n2) / n) + 1\n",
    "    std_dev = np.sqrt((2 * n1 * n2 * (2 * n1 * n2 - n)) / (n ** 2 * (n - 1)))\n",
    "    \n",
    "    z = (runs - mean_runs) / std_dev\n",
    "    p_value = 2 * norm.cdf(-abs(z))\n",
    "    \n",
    "    return runs, p_value\n",
    "\n",
    "# Example usage:\n",
    "x1 = [0, 1, 1, 0, 1]\n",
    "x2 = [1, 0, 1, 1, 0]\n",
    "\n",
    "test_statistic, p_value = run_test(x1, x2)\n",
    "print(\"Test Statistic:\", test_statistic)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd10c98b-dda1-410a-a98e-6788258a6329",
   "metadata": {},
   "source": [
    "## Test 69 The run test for randomness in a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f42c7b5c-956c-4fed-8549-a408dc1e57bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic: 0.2836832573067901\n"
     ]
    }
   ],
   "source": [
    "def run_test(data):\n",
    "    runs = []\n",
    "    current_run = 1\n",
    "    for i in range(1, len(data)):\n",
    "        if data[i] != data[i - 1]:\n",
    "            runs.append(current_run)\n",
    "            current_run = 1\n",
    "        else:\n",
    "            current_run += 1\n",
    "    runs.append(current_run)\n",
    "\n",
    "    n1 = sum(1 for run in runs if run == 1)\n",
    "    n2 = sum(1 for run in runs if run == 2)\n",
    "    \n",
    "    # Calculate the expected number of runs\n",
    "    expected_runs = ((2 * n1 * n2) / (n1 + n2)) + 1\n",
    "\n",
    "    # Calculate the test statistic\n",
    "    test_statistic = (len(runs) - expected_runs) / ((2 * n1 * n2 * (2 * n1 * n2 - n1 - n2)) ** 0.5)\n",
    "\n",
    "    return test_statistic\n",
    "\n",
    "# Example usage:\n",
    "data = [1, 0, 1, 1, 0, 0, 1, 1, 1, 0]\n",
    "test_statistic = run_test(data)\n",
    "print(\"Test statistic:\", test_statistic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642e7003-c03b-41f4-b221-71d11f734e62",
   "metadata": {},
   "source": [
    "## Test 70 The Wilcoxon–Mann–Whitney rank sum test for the randomness of signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dbf5675-f310-48ef-82fb-4a91b81450fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: 0.24433888871261045\n",
      "P-value: 0.806968367170738\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ranksums\n",
    "import numpy as np\n",
    "\n",
    "def wilcoxon_mann_whitney_sign_test(data):\n",
    "    \"\"\"\n",
    "    Performs the Wilcoxon-Mann-Whitney rank sum test for the randomness of signs.\n",
    "    \n",
    "    Parameters:\n",
    "        data (array-like): The input data.\n",
    "        \n",
    "    Returns:\n",
    "        statistic (float): The test statistic.\n",
    "        p_value (float): The p-value for the test.\n",
    "    \"\"\"\n",
    "    signs = np.sign(data)\n",
    "    statistic, p_value = ranksums(signs, np.zeros_like(signs))\n",
    "    return statistic, p_value\n",
    "\n",
    "# Example usage:\n",
    "data = np.random.normal(0, 1, 100)  # Example data, replace with your own data\n",
    "statistic, p_value = wilcoxon_mann_whitney_sign_test(data)\n",
    "print(\"Test Statistic:\", statistic)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
